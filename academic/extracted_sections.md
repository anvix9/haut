# Abstract

The increasing reliance on large language mod-
els (LLMs) in academic writing has led to a rise
in plagiarism. Existing AI-generated text clas-
sifiers have limited accuracy and often produce
false positives. We propose a novel approach
using natural language processing (NLP) tech-
niques, offering quantifiable metrics at both
sentence and document levels for easier inter-
pretation by human evaluators. Our method em-
ploys a multi-faceted approach, generating mul-
tiple paraphrased versions of a given question
and inputting them into the LLM to generate
answers. By using a contrastive loss function
based on cosine similarity, we match gener-
ated sentences with those from the student’s
response. Our approach achieves up to 94%
accuracy in classifying human and AI text, pro-
viding a robust and adaptable solution for pla-
giarism detection in academic settings. This
method improves with LLM advancements, re-
ducing the need for new model training or re-
configuration, and offers a more transparent
way of evaluating and detecting AI-generated
text.

# Introduction

In recent years, large language models (LLMs)
have demonstrated remarkable capabilities across
a wide range of natural language processing (NLP)
tasks, including text classification, sentiment anal-
ysis, translation, and question-answering (He et al.,
2023).

These foundational models exhibit immense po-
tential in tackling a diverse array of NLP tasks,
spanning from natural language understanding
(NLU) to natural language generation (NLG), and
even laying the groundwork for Artificial General
Intelligence (AGI) (Yang et al., 2023). In the world
of advanced LLMs, ChatGPT (2023) as an AI
model developed by OpenAI (2023b) has become
one of the most popular and widely used models,
setting new records for performance and flexibility

in many applications. According to the latest avail-
able data, ChatGPT (2023) currently has over 100
million users and the website currently generates
1 billion visitors per month (Duarte, 2023). While
ChatGPT has brought numerous benefits such as
it allows us to obtain information more effectively,
improves people’s writing skills etc., however, it
has also introduced considerable risks (OpenAI,
2023a).

A major risk associated with the growing depen-
dence on ChatGPT is the escalation of plagiarism in
academic writing (Khalil and Er, 2023), which sub-
sequently compromises the integrity and purpose
of assignments and examinations. Thanks to its
advanced training process and access to abundant
pre-training data sets, ChatGPT is capable of resem-
bling human-like language when provided with a
prompt (Joshi et al., 2023). It even exceeds human
performance in some academic writing while main-
taining authenticity and richness. Furthermore, hu-
mans are unable to accurately distinguish between
Human Generated Text (HGT) and Machine Gen-
erated Text (MGT), regardless of their familiarity
with ChatGPT (Herbold et al., 2023). These factors
present significant challenges in maintaining educa-
tional integrity and challenge the current paradigm
of how teachers teach.

Popular LLMs and AI-generated text detection
tools

To reduce potential plagiarism caused by the
use of LLMs, researchers have developed various

AI-generated text classifiers or tools such as Log-
Likelihood (Solaiman et al., 2019), RoBERTa-QA
(HC3) (Guo et al., 2023), GPTZero (2023), OpenAI
Classifier (OpenAI, 2023b), DetectGPT (Mitchell
et al., 2023), and Turntin (Fowler, 2023). Figure 1
lists popular LLMs used for text generation and
AI-generated text detection tools.

Existing approaches for detecting text generated
by language models have several limitations as
highlighted in Table 1. For instance, these tools

e
v
i
t
i
s
o
P
e
s
l
a
F
h
g
i
H

g
n

i

n
i
a
r
t
e
R

l
e
d
o
M

2
T
P
G
r
o
f

s
k
r
o
W

e
r
u
t
a
N
x
o
b
k
c
a
l
B

Current Method

✓ ✓ ✓ ✓
Log-Likelihood
✓ ✓ × ✓
RoBERTa-QA (HC3)
OpenAI Classifier ✓ ✓ × ✓
✓ ✓ ✓ ✓
DetectGPT
✓ ✓ × ✓
Turnitin

Table 1: Problems with current approaches

may rapidly become outdated due to technological
advancements, such as new versions of GPT mod-
els, necessitating classifier retraining and often re-
sulting in limited accuracy. Models trained specifi-
cally on one language model might not effectively
detect text generated by a different language model
(e.g., DetectGPT classifier works only on text gen-
erated using GPT2 (OpenAI, 2023b)). Addition-
ally, some detection tools provide non-quantitative
label results, and all possess a black-box nature
concerning prediction accuracy. Thus the predic-
tions made by such tools lack explainability and are
challenging for human evaluators to comprehend.
This issue leads to a high number of false positive
punishments in academic settings (Fowler, 2023).
We propose a novel approach for detecting pla-
giarized text, which focuses on NLP techniques.
Our approach offers more quantifiable metrics at
the sentence level, allowing for easier interpretation
by human evaluators and eliminating the black-box
nature of existing AI text detection methods. Our
approach is not limited to ChatGPT but can also
be applied to other LLMs such as BardAI (Google,
2023), Character.AI (Character.AI, 2023), and so
on, it also can adapt automatically as those LLMs
upgrade. This adaptability helps to ensure that it

does not become outdated quickly as technology
advances.

In evaluating our approach, we used the open
dataset known as the ChatGPT Comparison Cor-
pus (HC3) (Guo et al., 2023). This dataset con-
tains 10,000 questions and their corresponding an-
swers from both human experts and ChatGPT, cov-
ering a range of domains including open-domain,
computer science, finance, medicine, law, and psy-
chology. Our approach achieves 94% accuracy in
classifying between human answers and ChatGPT
answers in the HC3 data set.

The paper is structured as follows. Section 2 con-
tains a review of relevant literature. Our proposed
end-to-end approach for AI-text detection is de-
tailed in Section 3, where we describe the method
framework. In Section 4, we present our main re-
sults from the experimental evaluation. Lastly, we
summarize our findings and discuss future direc-
tions in Section 5, which serves as the conclusion.

# Method

In this section, we present our approach to effec-
tively compare and detect plagiarism in student
responses. Our method utilizes an advanced para-
phrasing model, a state-of-the-art language model,
and a contrastive loss function to deliver a com-
prehensive and transparent evaluation system. Fig-
ure 2 shows the different components of our pro-
posed model architecture.

3.1 Paraphrasing Model

To simulate the variety of questions a student might
pose to a large language model (LLM), we employ
a paraphrasing model (refer to Figure 2). This
model generates multiple paraphrased versions of
a given question, accounting for the diversity in
student queries and ensuring robustness in the de-
tection process.

Using Google’s T5 language model (Roberts and
Raffel, 2020) an initial dataset of questions is se-
lected and paraphrased. The T5 model is trained
on a large corpus of text, which enables it to un-
derstand the context and rephrase questions that
preserve the original meaning while introducing
variety. This model mimics the array of questions
students might ask an LLM, a crucial feature to
ensure robustness in the detection process.

For example, consider the following original
question Q1 from the Reddit ELI5 (HC3 dataset)
(Guo et al., 2023):

Q1 What is a hacker really doing? I’ve always
wanted to know why hackers are jamming on
their keyboards and what they can possibly be
doing that requires such precision and speed.
Please explain like I’m five.

The paraphrasing model generates the following
paraphrased versions:

P1 What do hackers actually do? I’ve always
been curious about why they type so fast on
their keyboards and what they’re doing that
needs such accuracy and quickness. Can you
explain it to me as if I were a five-year-old?

P2 I’ve always wondered what hackers are truly
up to when they’re typing rapidly on their
keyboards. What kind of tasks are they per-
forming that demand such skill and swiftness?
Please explain it in a simple way, as if I were
just five years old.

P3 What is it that hackers do when they’re furi-
ously typing on their keyboards? I’m curious
about the activities they’re involved in that
require such speed and precision. Could you
break it down for me in terms a five-year-old
would understand?

3.2 LLM Integration

Once we have the paraphrased questions, we input
them into an LLM. This model, particularly the
GPT-3.5-turbo from OpenAI ChatGPT (2023), is
adept at generating coherent and contextually ap-
propriate answers. Its proficiency stems from pre-
training on an extensive amount of textual data, al-
lowing it to provide accurate and relevant responses
to the paraphrased questions.

For example, we input the first paraphrased ques-
tion P1 into the LLM and generate the following
answer:

A1 Hackers are like computer experts who solve
puzzles. They use their keyboards to give com-
mands to computers to find secret information
or fix problems. They need to be fast and ac-
curate because computers follow instructions
very quickly, and one wrong command can
cause mistakes. Just like playing a game, they
need to be good at using their keyboards to
win the computer puzzle.

Model Architecture for our proposed method

We do similar generations for the other two para-

phrased versions of the question Q1.

3.3 Evaluation Process

To facilitate a detailed comparison between the
LLM-generated answers and student responses, we
break down each answer into individual sentences.
This granular approach enhances transparency and
allows for a more in-depth evaluation of potential
plagiarism.

For example, consider the LLM-generated an-
swer A1 and a human answer H1 for question Q1
from the Reddit ELI5 dataset:

H1 I’ve always wanted to know why hackers are
jamming on their keyboards In reality, this
doesn’t happen. This is done in movies to
make it look dramatic and exciting. Real com-
puter hacking involves staring at a computer
screen for hours of a time, searching a lot on
Google, muttering ¨hmmm änd various exple-
tives to oneself now and then, and stroking one
’s hacker - beard while occasionally tapping
on a few keys .", "Computers are stupid, they
don’t know what they are doing, they just do it.
If you tell a computer to give a cake to every
person that walks through the door, it will do.
Hackers are the people that get extra cake by
going around the building and back through
the door. GLaDOS however, will give you no
cake .", "Hackers have a deep and complete
understanding of a subject ( e.g. a machine or
computer program ). They change the behav-
ior of the subject to something that was never
intended or even thought it would be possible
by the creator of the subject .

We next do a pair-wise comparison between a

sentence in H1 and all the sentences in A1, A2, and
A3, to identify the AI generated sentence which is
most similar to H1.

3.4 Cosine Similarity

To compare two sentences we measure cosine sim-
ilarity between the embeddings for the sentences
generated using text-embedding-ada-002.
The use of cosine similarity on sentence level con-
textualembeddings captures semantic and syntac-
tic congruence between compared sentences. We
use the term Human-Machine (HM) comparison
for comparing sentence pairs involving a human-
generated sentence and a machine-generated sen-
tence. While Machine-Machine (MM) comparison
involves comparing two machine-generated sen-
tences.

3.5 Linear Discriminant Analysis

We apply Linear Discriminant Analysis (LDA)
(Tharwat et al., 2017) —a supervised classi-
fication method — to categorize sentences as
human- or AI-generated using cosine similar-
ity scores. These scores and their respective
category labels form our dataset, serving as
independent and dependent variables,
respec-
tively. The LDA model is trained using sklearn’s
LinearDiscriminantAnalysis class. The
trained model is then used to predict the probability
of a sentence in the test set being AI-generated.

To optimize classification, we explore a range
of threshold values from 0 to 1 in a binary system.
By assigning samples in datasets HM and MM to
categories 0 and 1 respectively, we can conduct the
LDA analysis on these two groups of datasets. Con-
sequently, we determine the optimal threshold for
classifying human-generated text and AI-generated

text awhere the accuracy is maximized.

# Conclusion

In conclusion, this research presents a novel and
effective method for detecting machine-generated
text in academic settings, offering a valuable contri-
bution to the field of plagiarism detection. By lever-
aging a comprehensive comparison technique, our
approach provides more accurate and explainable
evaluations compared to existing methods. The
sentence level quantifiable metrics facilitate eas-
ier interpretation for human evaluators, mitigating
the black-box nature of existing AI text detection
methods.

Our model is adaptable to various NLG mod-
els, including cutting-edge LLMs like BardAI and
Character.AI, ensuring its relevance and effective-
ness as technology continues to evolve. This
adaptability makes our approach a significant as-
set in maintaining academic integrity in the face
of rapidly advancing natural language processing
technologies.

Xinlei He, Xinyue Shen, Zeyuan Chen, Michael Backes,
and Yang Zhang. 2023. Mgtbench: Benchmarking
machine-generated text detection.

Steffen Herbold, Annette Hautli-Janisz, Ute Heuer,
Zlata Kikteva, and Alexander Trautsch. 2023. Ai,
write an essay for me: A large-scale comparison of
human-written versus chatgpt-generated essays.

Ishika Joshi, Ritvik Budhiraja, Harshal Dev, Jahnvi Ka-
dia, M. Osama Ataullah, Sayan Mitra, Dhruv Kumar,
and Harshal D. Akolekar. 2023. Chatgpt – a bless-
ing or a curse for undergraduate computer science
students and instructors?

Mohammad Khalil and Erkan Er. 2023. Will chatgpt
get you caught? rethinking of plagiarism detection.

Eric Mitchell, Yoonho Lee, Alexander Khazatsky,
Christopher D. Manning, and Chelsea Finn. 2023.
Detectgpt: Zero-shot machine-generated text detec-
tion using probability curvature.

OpenAI. 2023a. Gpt-4 technical report.

OpenAI. 2023b. Openai official website. https://

openai.com/. Accessed on May 15, 2023.

Adam Roberts and Colin Raffel. 2020. Exploring trans-
fer learning with T5: the text-to-text transfer trans-
former. Google AI Blog. Google AI Blog.

Irene Solaiman, Miles Brundage, Jack Clark, Amanda
Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford,
Gretchen Krueger, Jong Wook Kim, Sarah Kreps,
Miles McCain, Alex Newhouse, Jason Blazakis, Kris
McGuffie, and Jasmine Wang. 2019. Release strate-
gies and the social impacts of language models.

Ruixiang Tang, Yu-Neng Chuang, and Xia Hu. 2023.

The science of detecting llm-generated texts.

Alaa Tharwat et al. 2017. Linear discriminant analysis:

A detailed tutorial.

Jianguo Wang, Xiaomeng Yi, Rentong Guo, Hai Jin,
Peng Xu, Shengjun Li, Xiangyu Wang, Xiangzhou
Guo, Chengming Li, Xiaohai Xu, et al. 2021. Milvus:
A purpose-built vector data management system. In
Proceedings of the 2021 International Conference on
Management of Data, pages 2614–2627.

Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian
Han, Qizhang Feng, Haoming Jiang, Bing Yin, and
Xia Hu. 2023. Harnessing the power of llms in prac-
tice: A survey on chatgpt and beyond.

Future research directions include collecting ad-
ditional unbiased datasets for evaluation and com-
paring the performance of our model with other
detection tools. We also plan to explore the in-
corporation of different algorithms at the sentence
level, assembling them to achieve even better per-
formance. Moreover, we plan to employ stylometry
techniques to identify each student’s unique writ-
ing style as more data from their responses are
collected. This process will create a distinct signa-
ture based on the student’s writing patterns, making
it increasingly easy to detect plagiarism in future
submissions.

These efforts will further refine our model and
contribute to the ongoing pursuit of robust, trans-
parent, and adaptable plagiarism detection methods
in academia.

