Beyond Black Box AI-Generated Plagiarism Detection: From Sentence to
Document Level

Mujahid Ali Quidwai
New York University
maq4265@nyu.edu

Chunhui Li
Columbia University
cl4282@columbia.edu

Parijat Dube
IBM Research
pdube@us.ibm.com

3
2
0
2

n
u
J

3
1

]
L
C
.
s
c
[

1
v
2
2
1
8
0
.
6
0
3
2
:
v
i
X
r
a

Abstract

The increasing reliance on large language mod-
els (LLMs) in academic writing has led to a rise
in plagiarism. Existing AI-generated text clas-
sifiers have limited accuracy and often produce
false positives. We propose a novel approach
using natural language processing (NLP) tech-
niques, offering quantifiable metrics at both
sentence and document levels for easier inter-
pretation by human evaluators. Our method em-
ploys a multi-faceted approach, generating mul-
tiple paraphrased versions of a given question
and inputting them into the LLM to generate
answers. By using a contrastive loss function
based on cosine similarity, we match gener-
ated sentences with those from the student’s
response. Our approach achieves up to 94%
accuracy in classifying human and AI text, pro-
viding a robust and adaptable solution for pla-
giarism detection in academic settings. This
method improves with LLM advancements, re-
ducing the need for new model training or re-
configuration, and offers a more transparent
way of evaluating and detecting AI-generated
text.

1

Introduction

In recent years, large language models (LLMs)
have demonstrated remarkable capabilities across
a wide range of natural language processing (NLP)
tasks, including text classification, sentiment anal-
ysis, translation, and question-answering (He et al.,
2023).

These foundational models exhibit immense po-
tential in tackling a diverse array of NLP tasks,
spanning from natural language understanding
(NLU) to natural language generation (NLG), and
even laying the groundwork for Artificial General
Intelligence (AGI) (Yang et al., 2023). In the world
of advanced LLMs, ChatGPT (2023) as an AI
model developed by OpenAI (2023b) has become
one of the most popular and widely used models,
setting new records for performance and flexibility

in many applications. According to the latest avail-
able data, ChatGPT (2023) currently has over 100
million users and the website currently generates
1 billion visitors per month (Duarte, 2023). While
ChatGPT has brought numerous benefits such as
it allows us to obtain information more effectively,
improves people’s writing skills etc., however, it
has also introduced considerable risks (OpenAI,
2023a).

A major risk associated with the growing depen-
dence on ChatGPT is the escalation of plagiarism in
academic writing (Khalil and Er, 2023), which sub-
sequently compromises the integrity and purpose
of assignments and examinations. Thanks to its
advanced training process and access to abundant
pre-training data sets, ChatGPT is capable of resem-
bling human-like language when provided with a
prompt (Joshi et al., 2023). It even exceeds human
performance in some academic writing while main-
taining authenticity and richness. Furthermore, hu-
mans are unable to accurately distinguish between
Human Generated Text (HGT) and Machine Gen-
erated Text (MGT), regardless of their familiarity
with ChatGPT (Herbold et al., 2023). These factors
present significant challenges in maintaining educa-
tional integrity and challenge the current paradigm
of how teachers teach.

Figure 1: Popular LLMs and AI-generated text detection
tools

To reduce potential plagiarism caused by the
use of LLMs, researchers have developed various

AI-generated text classifiers or tools such as Log-
Likelihood (Solaiman et al., 2019), RoBERTa-QA
(HC3) (Guo et al., 2023), GPTZero (2023), OpenAI
Classifier (OpenAI, 2023b), DetectGPT (Mitchell
et al., 2023), and Turntin (Fowler, 2023). Figure 1
lists popular LLMs used for text generation and
AI-generated text detection tools.

Existing approaches for detecting text generated
by language models have several limitations as
highlighted in Table 1. For instance, these tools

e
v
i
t
i
s
o
P
e
s
l
a
F
h
g
i
H

g
n

i

n
i
a
r
t
e
R

l
e
d
o
M

2
T
P
G
r
o
f

s
k
r
o
W

e
r
u
t
a
N
x
o
b
k
c
a
l
B

Current Method

✓ ✓ ✓ ✓
Log-Likelihood
✓ ✓ × ✓
RoBERTa-QA (HC3)
OpenAI Classifier ✓ ✓ × ✓
✓ ✓ ✓ ✓
DetectGPT
✓ ✓ × ✓
Turnitin

Table 1: Problems with current approaches

may rapidly become outdated due to technological
advancements, such as new versions of GPT mod-
els, necessitating classifier retraining and often re-
sulting in limited accuracy. Models trained specifi-
cally on one language model might not effectively
detect text generated by a different language model
(e.g., DetectGPT classifier works only on text gen-
erated using GPT2 (OpenAI, 2023b)). Addition-
ally, some detection tools provide non-quantitative
label results, and all possess a black-box nature
concerning prediction accuracy. Thus the predic-
tions made by such tools lack explainability and are
challenging for human evaluators to comprehend.
This issue leads to a high number of false positive
punishments in academic settings (Fowler, 2023).
We propose a novel approach for detecting pla-
giarized text, which focuses on NLP techniques.
Our approach offers more quantifiable metrics at
the sentence level, allowing for easier interpretation
by human evaluators and eliminating the black-box
nature of existing AI text detection methods. Our
approach is not limited to ChatGPT but can also
be applied to other LLMs such as BardAI (Google,
2023), Character.AI (Character.AI, 2023), and so
on, it also can adapt automatically as those LLMs
upgrade. This adaptability helps to ensure that it

does not become outdated quickly as technology
advances.

In evaluating our approach, we used the open
dataset known as the ChatGPT Comparison Cor-
pus (HC3) (Guo et al., 2023). This dataset con-
tains 10,000 questions and their corresponding an-
swers from both human experts and ChatGPT, cov-
ering a range of domains including open-domain,
computer science, finance, medicine, law, and psy-
chology. Our approach achieves 94% accuracy in
classifying between human answers and ChatGPT
answers in the HC3 data set.

The paper is structured as follows. Section 2 con-
tains a review of relevant literature. Our proposed
end-to-end approach for AI-text detection is de-
tailed in Section 3, where we describe the method
framework. In Section 4, we present our main re-
sults from the experimental evaluation. Lastly, we
summarize our findings and discuss future direc-
tions in Section 5, which serves as the conclusion.

2 Related Work

The field of AI-generated text detection has gar-
nered significant interest, but only a few models
and tools have achieved widespread adoption. In
this section, we discuss state-of-the-art approaches,
the datasets used for training their classifiers, and
their limitations.

2.1 DetectGPT

DetectGPT (Mitchell et al., 2023) is a zero-shot
machine-generated text detection method that lever-
ages the negative curvature regions of an LLM’s
log probability function. The approach does not
require training a separate classifier, collecting a
dataset of real or generated passages, or watermark-
ing generated text. Despite its effectiveness, De-
tectGPT is limited to GPT-2 generated text, and its
performance may not extend to other LLMs (Tang
et al., 2023).

2.2 Human ChatGPT Comparison Corpus

(HC3)

Guo et al. (2023) introduced the HC3 dataset,
which contains tens of thousands of comparison
responses from both human experts and ChatGPT
(2023). They conducted comprehensive human
evaluations and linguistic analyses to study the
characteristics of ChatGPT’s responses, the dif-
ferences and gaps from human experts, and fu-
ture directions for LLMs. Furthermore, they built

three different detection systems to effectively de-
tect whether a text is generated by ChatGPT or
humans. However, this approach might still suf-
fer from high false positive rates and it does not
provide correct sentence-level comparison metrics.

2.3 OpenAI AI Text Classifier

The OpenAI AI Text Classifier (OpenAI, 2023b)
is a fine-tuned GPT model designed to predict the
likelihood of a piece of text being AI-generated.
This free tool aims to foster discussions on AI liter-
acy, but it has limitations: it requires a minimum
of 1,000 characters, can mislabel AI-generated and
human-written text, and can be evaded by editing
AI-generated text. Additionally, it also suffers from
high positive rates.

In our research, we aim to address the limitations
of these existing methods by developing a novel
approach for detecting plagiarized text, focusing
on natural language processing techniques that pro-
vide more quantifiable metrics and eliminate the
black-box nature of existing AI text detection meth-
ods

3 Our Method

In this section, we present our approach to effec-
tively compare and detect plagiarism in student
responses. Our method utilizes an advanced para-
phrasing model, a state-of-the-art language model,
and a contrastive loss function to deliver a com-
prehensive and transparent evaluation system. Fig-
ure 2 shows the different components of our pro-
posed model architecture.

3.1 Paraphrasing Model

To simulate the variety of questions a student might
pose to a large language model (LLM), we employ
a paraphrasing model (refer to Figure 2). This
model generates multiple paraphrased versions of
a given question, accounting for the diversity in
student queries and ensuring robustness in the de-
tection process.

Using Google’s T5 language model (Roberts and
Raffel, 2020) an initial dataset of questions is se-
lected and paraphrased. The T5 model is trained
on a large corpus of text, which enables it to un-
derstand the context and rephrase questions that
preserve the original meaning while introducing
variety. This model mimics the array of questions
students might ask an LLM, a crucial feature to
ensure robustness in the detection process.

For example, consider the following original
question Q1 from the Reddit ELI5 (HC3 dataset)
(Guo et al., 2023):

Q1 What is a hacker really doing? I’ve always
wanted to know why hackers are jamming on
their keyboards and what they can possibly be
doing that requires such precision and speed.
Please explain like I’m five.

The paraphrasing model generates the following
paraphrased versions:

P1 What do hackers actually do? I’ve always
been curious about why they type so fast on
their keyboards and what they’re doing that
needs such accuracy and quickness. Can you
explain it to me as if I were a five-year-old?

P2 I’ve always wondered what hackers are truly
up to when they’re typing rapidly on their
keyboards. What kind of tasks are they per-
forming that demand such skill and swiftness?
Please explain it in a simple way, as if I were
just five years old.

P3 What is it that hackers do when they’re furi-
ously typing on their keyboards? I’m curious
about the activities they’re involved in that
require such speed and precision. Could you
break it down for me in terms a five-year-old
would understand?

3.2 LLM Integration

Once we have the paraphrased questions, we input
them into an LLM. This model, particularly the
GPT-3.5-turbo from OpenAI ChatGPT (2023), is
adept at generating coherent and contextually ap-
propriate answers. Its proficiency stems from pre-
training on an extensive amount of textual data, al-
lowing it to provide accurate and relevant responses
to the paraphrased questions.

For example, we input the first paraphrased ques-
tion P1 into the LLM and generate the following
answer:

A1 Hackers are like computer experts who solve
puzzles. They use their keyboards to give com-
mands to computers to find secret information
or fix problems. They need to be fast and ac-
curate because computers follow instructions
very quickly, and one wrong command can
cause mistakes. Just like playing a game, they
need to be good at using their keyboards to
win the computer puzzle.

Figure 2: Model Architecture for our proposed method

We do similar generations for the other two para-

phrased versions of the question Q1.

3.3 Evaluation Process

To facilitate a detailed comparison between the
LLM-generated answers and student responses, we
break down each answer into individual sentences.
This granular approach enhances transparency and
allows for a more in-depth evaluation of potential
plagiarism.

For example, consider the LLM-generated an-
swer A1 and a human answer H1 for question Q1
from the Reddit ELI5 dataset:

H1 I’ve always wanted to know why hackers are
jamming on their keyboards In reality, this
doesn’t happen. This is done in movies to
make it look dramatic and exciting. Real com-
puter hacking involves staring at a computer
screen for hours of a time, searching a lot on
Google, muttering ¨hmmm änd various exple-
tives to oneself now and then, and stroking one
’s hacker - beard while occasionally tapping
on a few keys .", "Computers are stupid, they
don’t know what they are doing, they just do it.
If you tell a computer to give a cake to every
person that walks through the door, it will do.
Hackers are the people that get extra cake by
going around the building and back through
the door. GLaDOS however, will give you no
cake .", "Hackers have a deep and complete
understanding of a subject ( e.g. a machine or
computer program ). They change the behav-
ior of the subject to something that was never
intended or even thought it would be possible
by the creator of the subject .

We next do a pair-wise comparison between a

sentence in H1 and all the sentences in A1, A2, and
A3, to identify the AI generated sentence which is
most similar to H1.

3.4 Cosine Similarity

To compare two sentences we measure cosine sim-
ilarity between the embeddings for the sentences
generated using text-embedding-ada-002.
The use of cosine similarity on sentence level con-
textualembeddings captures semantic and syntac-
tic congruence between compared sentences. We
use the term Human-Machine (HM) comparison
for comparing sentence pairs involving a human-
generated sentence and a machine-generated sen-
tence. While Machine-Machine (MM) comparison
involves comparing two machine-generated sen-
tences.

3.5 Linear Discriminant Analysis

We apply Linear Discriminant Analysis (LDA)
(Tharwat et al., 2017) —a supervised classi-
fication method — to categorize sentences as
human- or AI-generated using cosine similar-
ity scores. These scores and their respective
category labels form our dataset, serving as
independent and dependent variables,
respec-
tively. The LDA model is trained using sklearn’s
LinearDiscriminantAnalysis class. The
trained model is then used to predict the probability
of a sentence in the test set being AI-generated.

To optimize classification, we explore a range
of threshold values from 0 to 1 in a binary system.
By assigning samples in datasets HM and MM to
categories 0 and 1 respectively, we can conduct the
LDA analysis on these two groups of datasets. Con-
sequently, we determine the optimal threshold for
classifying human-generated text and AI-generated

text awhere the accuracy is maximized.

4 Experimental Evaluation

In our experimental evaluation, we aim to measure
the accuracy of our approach in detecting similar-
ities between human and machine-generated an-
swers. We use the Human ChatGPT Comparison
Corpus (HC3) dataset, which contains human and
ChatGPT-generated answers to the same questions.

4.1 Dataset Preparation

For our analysis, we prepare two datasets to evalu-
ate our model at the sentence and document levels.
We use the HC3 dataset for sentence-level evalua-
tion and then we did a summation over sentence-
level cosine similarity to get the average similarity
for the document. Further, to evaluate generaliza-
tion performance of our model, we use GPT-wiki-
intro dataset (Aaditya Bhat, 2023) for document-
level evaluation and comparison with other models.

4.1.1 Sentence-level Dataset: HC3
We first use the HC3 dataset, which contains ques-
tions and corresponding human and machine re-
sponses. The HC3 dataset has an additional ma-
chine response for each question, resulting in two
machine-generated answers.

Next, we break down each answer for a given
question into individual sentences, creating a
dataset of roughly 43,000 sentence-level compar-
isons for machine-machine (MM) and human-
machine (HM) categories. We use this dataset to
compare the human response to the machine re-
sponse at the sentence level, as well as compare
the machine responses to each other at the sentence
level using cosine similarity. Some example cosine
similarity values for HM and MM categories are
presented in Table 2.

HM

MM

CS
0.785
0.826
0.690
0.778
0.899

Label
0
0
0
0
0

CS
0.846
0.824
0.827
0.824
0.824

Label
1
1
1
1
1

Table 2: Example results of cosine similarity (CS) on
HM and MM sample with their corresponding categori-
cal label (0,1)

Figure 3 shows the distribution of cosine similar-
ity for HM and MM. For a visual representation of

the cosine similarity scores distribution, we gener-
ate a Kernel Density Estimation (KDE) plot (Chen,
2017). We also calculate the mean and standard
deviation of these scores (see Table 3) for sentence
level in HM and MM samples, providing insights
into the data. While the mean of the two classes is
significantly different, they also have high standard
deviations. This dataset is to be used to train and
test our LDA model at the sentence level.

Table 4 shows the threshold value used in the
LDA classifier and the corresponding accuracy on
the test set.

Figure 3: Distribution of cosine similarity at sentence
level for HM and MM.

4.1.2 Document-Level Dataset: HC3

For a comprehensive understanding, we also con-
duct a document-level analysis utilizing the HC3
dataset. Rather than dissecting the responses into
separate sentences, this level of examination treats
the entire response as a single unit.

The document-level dataset is constructed by
averaging the highest cosine similarity scores
from the sentence-level comparison within each
response. This approach ensures that the most
closely matched sentences significantly impact the
document-level similarity metric, thereby empha-
sizing the presence of highly similar sentences in
the text. This similarity value serves as the foun-
dation for our LDA model at the document level,
allowing for a macroscopic comparison of the ma-
chine and human responses.

The distribution of cosine similarity at the doc-
ument level is shown in Figure 4. Table 5 pro-
vides the mean and standard deviation of cosine
similarity scores for HM and MM samples in the
document level dataset.

Statistic
Mean
Standard Deviation

Human-Machine (HM) Machine-Machine (MM)

0.7309
0.1016

0.8527
0.0813

Table 3: Sentence Level Cosine Similarity Statistics

LDA Model Result Value
0.40
0.80

Best Threshold
Accuracy

Table 4: LDA Model Results: Sentence level

Figure 4: Distribution of cosine similarity at the Docu-
ment level for HM and MM

The LDA classifier’s threshold value and the
corresponding accuracy on the test set for the
document-level analysis are presented in Table 6.
Observe that, in contrast to sentence level statistics
(Table 3), the standard deviation of the two classes
under document level comparison (Table 5) are
smaller thereby resulting in a more discriminant
classifier.

4.2 Experimental Setup

Using the prepared dataset, we conduct a series
of experiments to assess the performance of our
proposed method in various plagiarism scenarios.
All the elements from the test set i.e., questions
and corresponding student answers, including origi-
nal and paraphrased questions alongside their corre-
sponding AI-generated answers, are subsequently
stored in a vector database, more specifically, Mil-
vus (Wang et al., 2021), an open-source vector
database. This step ensures efficient data man-
agement, comparison, and high-speed searching
of vector data. We incorporate FastText, a module
developed by Facebook (Bojanowski et al., 2017),

for vector ranking. The vectors representing para-
phrased answers are ranked, creating a hierarchy of
sentences based on similarity. A vector embedding
generator from OpenAI aids in transforming the
text into numerical form, allowing machine learn-
ing algorithms to process it. This transformation
is pivotal for comparing student responses with
AI-generated answers.

4.3 Results and Analysis

From Table 4 and Table 6 we observe that the
LDA classifier works better at the document level
compared to the sentence level. We next conduct
the document level evaluation of our model on the
GPT-wiki-intro dataset. This dataset comprises
questions along with their corresponding GPT-2
generated introductions and human-written intro-
ductions from Wikipedia articles. We perform
document-level analysis on the first 100 examples
from the GPT-wiki-intro dataset by comparing the
AI-generated introductions to the human-written in-
troductions, as well as comparing the AI-generated
introductions to each other.

Our evaluation aims to demonstrate the explain-
ability of our tool and its ability to provide both
sentence and document level analysis. By com-
paring our results with existing benchmarks, we
highlight the advantages of our approach in detect-
ing plagiarism more effectively and transparently.
Our model is compared with two state-of-the-art
(SOTA) models: HC3 and OpenAI’s text classifier.
In order to evaluate the effectiveness of using the
proposed paraphrasing model, we used two ver-
sions of our model, a model without paraphrasing
(A) and a model employing paraphrasing (B) on
the test set. This allows us to directly assess the
impact of paraphrasing on model performance.

Confusion matrices for all the models under eval-
uation are shown in Table 7. While derived per-
formance metrics (F1 score, precision, and recall)
are provided in Table 8. We observe no improve-
ment in model performance with paraphrasing on
this data set. We plan to investigate other potential
approaches to improve model performance includ-
ing varying the temperature and P value (OpenAI,

Statistic
Mean
Standard Deviation

Human-Machine (HM) Machine-Machine (MM)

0.7343
0.0447

0.8527
0.0681

Table 5: Document Level Cosine Similarity Statistics

LDA Model Result Value
0.66
0.94

Best Threshold
Accuracy

Table 6: LDA Model Results: Document level

2023a) of LLM used for answer generation. We
also plan to study our model performance on other
datasets for a robust evaluation of the value of para-
phrasing.

Predicted 0 Predicted 1

RoBERTa-QA

Actual 0
Actual 1

91
77

OpenAI Classifier

Actual 0
Actual 1

64
98

Our Model-A

Actual 0
Actual 1

99
90

Our Model-B

Actual 0
Actual 1

98
91

9
23

36
2

1
10

2
9

Table 7: Confusion matrices for SOTA models and our
model tested on GPT-wiki-intro dataset. Our model per-
formance on Class 0 is better than both RoBERT-QA
and Open AI Classifier, while on Class 1 our perfor-
mance is better than RoBERTa-QA. Our Model-B uses
paraphrasing.

Model

Precision Recall

F1

RoBERTa-QA
OpenAI Classifier
Our Model-A
Our Model-B

0.91
0.64
0.99
0.98

0.54
0.39
0.52
0.52

0.68
0.49
0.69
0.68

Table 8: Document level F1 score, precision, and recall
of the models. Our Model-B uses paraphrasing.

Our model provides the probability of a text be-

ing AI-generated, both at sentence and document
levels, enhancing transparency for evaluators ex-
amining potential plagiarism. For each sentence in
a test document - in this case, a student response
- the model calculates the probability of that sen-
tence being LLM-generated. When utilizing the
Reddit ELI5 (HC3 dataset), our model contrasts
the human response with the LLM response on
a sentence-by-sentence basis, as demonstrated in
Table 9. This added transparency makes it easier
for human evaluators to interpret the results and
contributes to the elimination of the black-box na-
ture often associated with existing AI text detection
methods. To summarize, our method:

• Effectively generates diverse paraphrased
questions using an advanced paraphrasing
model.

• Produces accurate and contextually appropri-
ate answers with the state-of-the-art LLM.
• Provides a comprehensive and transparent
sentence-level evaluation, enabling the de-
tection of subtle instances of plagiarism that
might be overlooked by traditional methods.

5 Conclusion

In conclusion, this research presents a novel and
effective method for detecting machine-generated
text in academic settings, offering a valuable contri-
bution to the field of plagiarism detection. By lever-
aging a comprehensive comparison technique, our
approach provides more accurate and explainable
evaluations compared to existing methods. The
sentence level quantifiable metrics facilitate eas-
ier interpretation for human evaluators, mitigating
the black-box nature of existing AI text detection
methods.

Our model is adaptable to various NLG mod-
els, including cutting-edge LLMs like BardAI and
Character.AI, ensuring its relevance and effective-
ness as technology continues to evolve. This
adaptability makes our approach a significant as-
set in maintaining academic integrity in the face
of rapidly advancing natural language processing
technologies.

Xinlei He, Xinyue Shen, Zeyuan Chen, Michael Backes,
and Yang Zhang. 2023. Mgtbench: Benchmarking
machine-generated text detection.

Steffen Herbold, Annette Hautli-Janisz, Ute Heuer,
Zlata Kikteva, and Alexander Trautsch. 2023. Ai,
write an essay for me: A large-scale comparison of
human-written versus chatgpt-generated essays.

Ishika Joshi, Ritvik Budhiraja, Harshal Dev, Jahnvi Ka-
dia, M. Osama Ataullah, Sayan Mitra, Dhruv Kumar,
and Harshal D. Akolekar. 2023. Chatgpt – a bless-
ing or a curse for undergraduate computer science
students and instructors?

Mohammad Khalil and Erkan Er. 2023. Will chatgpt
get you caught? rethinking of plagiarism detection.

Eric Mitchell, Yoonho Lee, Alexander Khazatsky,
Christopher D. Manning, and Chelsea Finn. 2023.
Detectgpt: Zero-shot machine-generated text detec-
tion using probability curvature.

OpenAI. 2023a. Gpt-4 technical report.

OpenAI. 2023b. Openai official website. https://

openai.com/. Accessed on May 15, 2023.

Adam Roberts and Colin Raffel. 2020. Exploring trans-
fer learning with T5: the text-to-text transfer trans-
former. Google AI Blog. Google AI Blog.

Irene Solaiman, Miles Brundage, Jack Clark, Amanda
Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford,
Gretchen Krueger, Jong Wook Kim, Sarah Kreps,
Miles McCain, Alex Newhouse, Jason Blazakis, Kris
McGuffie, and Jasmine Wang. 2019. Release strate-
gies and the social impacts of language models.

Ruixiang Tang, Yu-Neng Chuang, and Xia Hu. 2023.

The science of detecting llm-generated texts.

Alaa Tharwat et al. 2017. Linear discriminant analysis:

A detailed tutorial.

Jianguo Wang, Xiaomeng Yi, Rentong Guo, Hai Jin,
Peng Xu, Shengjun Li, Xiangyu Wang, Xiangzhou
Guo, Chengming Li, Xiaohai Xu, et al. 2021. Milvus:
A purpose-built vector data management system. In
Proceedings of the 2021 International Conference on
Management of Data, pages 2614–2627.

Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian
Han, Qizhang Feng, Haoming Jiang, Bing Yin, and
Xia Hu. 2023. Harnessing the power of llms in prac-
tice: A survey on chatgpt and beyond.

Future research directions include collecting ad-
ditional unbiased datasets for evaluation and com-
paring the performance of our model with other
detection tools. We also plan to explore the in-
corporation of different algorithms at the sentence
level, assembling them to achieve even better per-
formance. Moreover, we plan to employ stylometry
techniques to identify each student’s unique writ-
ing style as more data from their responses are
collected. This process will create a distinct signa-
ture based on the student’s writing patterns, making
it increasingly easy to detect plagiarism in future
submissions.

These efforts will further refine our model and
contribute to the ongoing pursuit of robust, trans-
parent, and adaptable plagiarism detection methods
in academia.

References

Aaditya Bhat. 2023. Gpt-wiki-intro (revision 0e458f5).

Piotr Bojanowski, Edouard Grave, Armand Joulin, and
Tomas Mikolov. 2017. Enriching word vectors with
subword information. Transactions of the Associa-
tion for Computational Linguistics, 5:135–146.

Character.AI. 2023. Character.ai. https://beta.
character.ai/. Accessed on May 15, 2023.

ChatGPT. 2023. Chatgpt official website. https:
//openai.com/blog/chatgpt. Accessed on
May 15, 2023.

Yen-Chi Chen. 2017. A tutorial on kernel density esti-

mation and recent advances.

Fabio Duarte. 2023.

Number of chatgpt users
(2023). https://explodingtopics.com/
blog/chatgpt-users. Accessed on May 15,
2023.

for

Geoffrey A. Fowler. 2023. We tested a new chatgpt-
it flagged an innocent
https://www.washingtonpost.

detector
student.
com/technology/2023/04/01/
chatgpt-cheating-detection-turnitin/.

teachers.

Google. 2023. Bardai. https://blog.google/
technology/ai/try-bard/. Accessed on
May 15, 2023.

GPTZero. 2023. Gptzero official website. https:
//gptzero.me/. Accessed on May 15, 2023.

Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang,
Jinran Nie, Yuxuan Ding, Jianwei Yue, and Yupeng
Wu. 2023. How close is chatgpt to human experts?
comparison corpus, evaluation, and detection.

LLM Response
This can involve a lot of trial
and error, which is why hackers
might seem to be "jamming on
their keyboards" as they try dif-
ferent approaches.
Overall, hacking can be a com-
plex and technical activity that
requires a lot of knowledge and
skill.
Hacking can involve a lot of typ-
ing and computer use, because
hackers often use special soft-
ware and programs to try to find
weaknesses in a system or net-
work.
This can involve a lot of trial
and error, which is why hackers
might seem to be "jamming on
their keyboards" as they try dif-
ferent approaches.
A hacker is someone who uses
their computer skills to try to
gain access to systems or net-
works without permission.
This can involve a lot of trial
and error, which is why hackers
might seem to be "jamming on
their keyboards" as they try dif-
ferent approaches.
They might also use tools to
try to guess passwords or to
find ways to get around security
measures.
Hacking can involve a lot of typ-
ing and computer use, because
hackers often use special soft-
ware and programs to try to find
weaknesses in a system or net-
work.

Hackers might do this for a va-
riety of reasons, such as to steal
information, to cause damage or
disruption, or just for the chal-
lenge of it.
Hackers might do this for a va-
riety of reasons, such as to steal
information, to cause damage or
disruption, or just for the chal-
lenge of it.

Human Response
Computers are stupid , they do
n’t know what they are doing ,
they just do it.

Cosine Similarity
0.8087

Hackers have a deep and com-
plete understanding of a subject
(e.g., a machine or computer
program).
A machine or computer pro-
gram.

0.8753

0.8154

GLaDOS however , will give
you no cake.

0.7472

Hackers are the people that get
extra cake by going around the
building and back through the
door.
I ’ve always wanted to know
why hackers are jamming on
their keyboards In reality , this
does n’t happen.

If you tell a computer to give a
cake to every person that walks
through the door , it will do.

Real computer hacking involves
staring at a computer screen for
hours of a time , searching a lot
on Google , muttering " hmmm
" and various expletives to one-
self now and then , and stroking
one ’.
They change the behavior of the
subject to something that was
never intended or even thought
it would be possible by the cre-
ator of the subject.
This is done in movies to make
it look dramatic and exciting.

0.8677

0.8641

0.7735

0.8846

0.7937

0.7676

Table 9: This table depicts the sentence-level comparison of responses to Question 1 Q1, given by a human H1
and a Large Language Model A1. The cosine similarity values, derived from embeddings, represent the highest
similarity between each pair of sentences in the human and LLM responses.


