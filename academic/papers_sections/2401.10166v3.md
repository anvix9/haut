# Abstract

Designing computationally efficient network architectures persists as an ongoing
necessity in computer vision. In this paper, we transplant Mamba, a state-space lan-
guage model, into VMamba, a vision backbone that works in linear time complexity.
At the core of VMamba lies a stack of Visual State-Space (VSS) blocks with the
2D Selective Scan (SS2D) module. By traversing along four scanning routes, SS2D
helps bridge the gap between the ordered nature of 1D selective scan and the non-
sequential structure of 2D vision data, which facilitates the gathering of contextual
information from various sources and perspectives. Based on the VSS blocks, we
develop a family of VMamba architectures and accelerate them through a succes-
sion of architectural and implementation enhancements. Extensive experiments
showcase VMambaâ€™s promising performance across diverse visual perception tasks,
highlighting its advantages in input scaling efficiency compared to existing bench-
mark models. Source code is available at https://github.com/MzeroMiko/VMamba.

