# Introduction

In academia, a way to encourage students utilizing all learning opportunities and experiences is to properly maintain

academic integrity in the courses . Students need to complete any exams and assessments with their best effort.

Further, they need to actively engage with the instructors (and tutors).

Authors‚Äô addresses: Michael Sheinman Orenstrakh, michael.sheinmanorenstrakh@mail.utoronto.ca, University of Toronto Mississauga, Mississauga,
Canada; Oscar Karnalim, oscar.karnalim@it.maranatha.edu, Maranatha Christian University, Bandung, Indonesia; Carlos An√≠bal Su√°rez, carasuar@
espol.edu.ec, Escuela Superior Polit√©cnica del Litoral, Guayaquil, Ecuador; Michael Liut, michael.liut@utoronto.ca, University of Toronto Mississauga,
Mississauga, Canada.

Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party
components of this work must be honored. For all other uses, contact the owner/author(s).

¬© 2023 Copyright held by the owner/author(s).
Manuscript submitted to ACM

Manuscript submitted to ACM

1

3
2
0
2

l
u
J

0
1

]
L
C
.
s
c
[

1
v
1
1
4
7
0
.
7
0
3
2
:
v
i
X
r
a

2

Michael Sheinman Orenstrakh, Oscar Karnalim, Carlos An√≠bal Su√°rez, and Michael Liut

Although Artificial Intelligence (AI) can foster education , it might be misused to breach academic integrity.

Paraphrasing tools  and code obfuscation tools  for example, are misused to cover up evidence for plagiarism (a

breach of academic integrity about copying one‚Äôs work and reusing it without proper acknowledgment ).

Misuse of AI chatbots with large language models (LLM)  such as ChatGPT1 is another trending threat for
breaching academic integrity. Students can complete exams or assessments with limited effort, resulting in questionable

performance; it is unclear whether the learning objectives are actually met. The misuse can be considered as contract

cheating (i.e., getting help in exchange for mutual incentives ) since AI chatbots provide responses in exchange for

additional user data. However, considering AI responses are generated based on other people‚Äôs textual data without

proper acknowledgment, we believe it is more justifiable to consider the misuse as plagiarism.

While checking student work for plagiarism, instructors are often aided by automated detectors. A number of

detectors have been developed to detect whether a work is a result of LLM. Two of them are GPT-2 Output Detector 

and Giant Language model Test Room (GLTR) . Nevertheless, due to the recency of misuse of AI chatbots, Computing

educators might have limited information about publicly available detection detectors. Further, it is challenging to

choose the most suitable detector for their teaching environment. To the best of our knowledge, there are no empirical

studies comparing the detectors in terms of effectiveness.

In response to the aforementioned gaps, we investigate LLM-generated text detectors and formulate the following

research question (RQ): ‚ÄúHow effective are LLM-generated text detectors?‚Äù

It is clear that there is a need in the community to understand if the currently available detectors are able to detect

LLM-generated content  and what there reliability is.

As an additional contribution, we also report our experience in using the LLM-generated text detectors. It might be

useful for readers interested in employing those detectors in their classrooms.

# Method

This section discusses how the research question stated in the introduction would be addressed and our preliminary

work to discover publicly available LLM-generated text detectors.

We collected historical assignment data dating back to 2016 from two publicly funded research-focused institutions,

one in North America and one in South America. The data collected was from upper-year undergraduate computer

science and engineering students.

We analyzed a total of 164 submissions (124 were submitted by humans, 30 were generated using ChatGPT, and

10 were generated by ChatGPT and altered using the Quillbot paraphrasing tool) and compared them against eight

LLM-generated text detectors. This results in a total of 1, 312 prediction results.

Of the 164 submissions, 134 were written in English (20 of which were generated by a LLM, and another 10 which

were LLM-generated and paraphrased) and 20 were written in Spanish (10 of which were AI-generated). The submissions

were collected between 2016 and 2018 (prior to the release of ChatGPT), and were made in ‚Äúdatabases‚Äù, ‚Äúnetworking‚Äù,

and a ‚Äúfinal thesis project‚Äù course. These courses were specifically selected as they are upper-year computer science

major courses that touch on a mix of systems and theory (databases and networking), as well as technical writing in

computer science with a programming/development component (final thesis project). The students in these courses

were primarily in a computer science major. It should also be noted that Spanish was selected as an alternative language

to analyse because it is one of the world‚Äôs most popular languages, and some of the authors have experience writing

and evaluating technical material in this language.

The assessments analyzed in this study (see Table 1) are taken from three undergrad courses. The first course is a

databases course offered to third-year computer science students in their first or second semester. It is a mix of database

theory and practical systems application. There are 101 paper submissions from this course which involved a final

assessment where students wrote a report analyzing two industry players and their use of databases and data centers,

this was written in English.

10https://edition.cnn.com/2023/01/26/tech/chatgpt-passes-exams/index.html
11https://theconversation.com/chatgpt-students-could-use-ai-to-cheat-but-its-a-chance-to-rethink-assessment-altogether-198019

Manuscript submitted to ACM

Detecting LLM-Generated Text in Computing Education

5

Table 1. Questions analyzed from submissions

Course
Databases

Networking

Thesis Project

Question
Write a report analyzing two industry players
and their use of databases and data centers. Dis-
cuss the efficiency, scalability, and social impact.
Implement the NOVEL-SMTP and NEO-SMTP
email protocols using only UDP at the transport
layer.
Continuous Improvement and Operational Ex-
cellence in Manufacturing and Industrial Pro-
cesses.

The second course is a networking course offered to third-year computer science students in their second semester. It

is a mix of theoretical concepts and practical system application. There are 13 paper submissions from this course which

involved an exam question where students explain how they would implement the NOVEL-SMTP and NEO-SMTP

email protocols using only UDP, this was written in English.

The third course is a final thesis project course offered to fourth-year computer science students throughout their

final year of study (across both semesters). It is meant to bridge theory and practice to develop something that can

be used/implemented in the real world. There are 10 paper submissions from this course which involved improving

computing systems and engineering processes in their local community, this was written in Spanish.

Due to the character limitations, data below 1,000 characters was excluded and data above 2,500 characters was

truncated to the last complete sentence. This ensures the input data fits within the range of all detectors. As many

LLM-generated text detection platforms have a 2,500 character maximum, to ensure fairness across platform, we used

2,500 characters as our upper-bound.

LLM-generated texts were created with the help of ChatGPT12, a popular LLM. The handouts were parsed to prompts
by removing irrelevant information (course code, deadlines, submission instruction) so the prompts only contain the

core requirements of the task. These prompts were then fed into ChatGPT to generate a solution to the assignment.

It should be noted, the authors mined through over 2, 000 submissions in programming, data structures and algorithms,

and compilers courses, however, the submission data varied too much for the content to easily be extracted and analyzed

for detectors. Often due to a lack of context after removing any code. The selected submissions were purely writing-based

and did not involve coding components, they did in some cases discuss theoretical concepts in computer science.

Finally, all of the detectors were tested in April 2023.

3.1 Discovering Publicly Available LLM-generated Text Detectors

Publicly available LLM-generated text detectors were discovered from January to February 2023 from social media (i.e.,

Twitter, Facebook, and blogs), online news, and previous literature on LLM-generated text detection (GPT-2, GLTR).

Public interest in LLM-generated text detectors followed the release of GPTZero which went viral on January, 2023.

After GPTZero, many other companies launched their own LLM-generated text detectors.

A number of LLM-generated text detectors were discovered but we limited this study to LLM-generated text detectors

that appear to offer proprietary solutions to LLM-generated text detection. We found that some LLM-generated text

detectors are likely to be replicas of open source work (GPT-2) and hence we excluded such detectors from the study.

12https://openai.com/blog/chatgpt

Manuscript submitted to ACM

6

Michael Sheinman Orenstrakh, Oscar Karnalim, Carlos An√≠bal Su√°rez, and Michael Liut

Table 2. Discovered publicly available LLM-generated text detectors; model info refers to how detailed the information of the used
LLM (complete, partial, and none)

Name

Link

GPT-2 Output
Detector
GLTR
CopyLeaks

GPTZero
AI Text Classi-
fier
Originality
GPTKit
CheckForAI

https://openai-openai-
detector.hf.space/
http://gltr.io/dist/index.html
https://copyleaks.com/
features/ai-content-detector
https://gptzero.me/
https://platform.openai.com/
ai-text-classifier
https://originality.ai/
https://gptkit.ai/
https://checkforai.com/

Model Info

Complete

Complete
None

Partial
Partial

None
Partial
Partial

We identified eight such publicly available LLM-generated text detectors, as shown in Table 2. Two of them (GPT-2

Output Detector and GLTR) are featured with technical reports .

GPT-2 Output Detector  is a LLM-generated text detector based on the RoBERTa large pretrained model .
RoBERTa is a transformers model trained on a large corpus of raw English data. The GPT-2 Output Detector starts with

the pre-trained ROBERTA-large model and trains a classifier for web data and the GPT-2 output dataset. The GPT-2

Detector returns the probability that an input text is real on GPT-2 text with accuracy of 88% at 124 million parameters

and 74% at 1.5 billion parameters . The detector is limited to the first 510 tokens, although there are extensions that

extend this limit .

GLTR  is a detector that applies statistical methods to detect GPT-2 text. The model is based on three simple tests:
the probability of the word, the absolute rank of a word, and the entropy of the predicted distribution. This detector

shows an interface where each word is highlighted along with a top-k class for that word.

The GLTR detector does not provide quantifiable overall probability that a text is AI-generated. To make a fair

comparison between GLTR and other detectors, we define a detector on top of GLTR to make probability predictions

using the normal distribution. We compute an average ùúá and a standard deviation ùúé over a sample dataset of 20 human
and 20 ChatGPT submissions. The results were ùúá = 35.33, and ùë† = 15.68. We then used those results to normalize a
prediction by computing the standard score of a data point ùë• using ùë• ‚àíùúá
. This score is sent as input to the sigmoid
ùë†
function to obtain a probability prediction.

GPTZero was the first detector  to claim to detect ChatGPT data. The original version of the detector used
two measures: perplexity and burstiness. Perplexity refers to a measurement of how well GPT-2 can predict the next

word in the text. This appears similar to the way the GLTR detector works . The second measure is burstiness: the

distribution of sentences. The idea is that humans tend to write with bursts of creativity and are more likely to have

a mix of short and long sentence. The current version of GPTZero gives four classes of results. Table 3 shows how

different classes are interpreted as probability. GPTZero claims an 88% accuracy for human text and 72% accuracy for

AI text for this detector .

Manuscript submitted to ACM

Detecting LLM-Generated Text in Computing Education

7

Table 3. GPTZero accuracy interpretation.

Category

AI Probability

Entirely written by human
Likely entirely human, but some
sentences have low perplexity
May contain parts written by AI
Entirely written by AI

0%
20%

60%
100%

Table 4. AI Text Classifier interpretation.

Category

Very unlikely
Unlikely
Unclear
Possibly
Likely

Internal Probability

Interpretation

<0.1
0.1 - 0.45
0.45 - 0.9
0.9 - 0.98
>0.98

0%
20%
50%
75%
100%

Table 5. CheckForAI accuracy interpretation.

Category

Low Risk
Medium Risk
High Risk
Very High Risk

AI Probability

0%
60%
80%
100%

AI Text Classifier is OpenAI‚Äôs 2023 model fine tuned to distinguish between human-written and AI-generated
text . The model is trained on text generated from 34 models from 5 different organization. The model provides 5

different categories for the results based on the internal probabilities the model provides. Table 4 shows how different

classes are interpreted as probability. The interpretations are based on the final category, not the internal model. Usage

of this classifier requires at least 1,000 characters.

GPTKit uses an ensemble of 6 other models, including DistilBERT , GLTR, Perplexity, PPL, RoBERTa , and
RoBERTa (base). The predictions of these models are used to form an overall probability that a text is LLM-generated.

However, the exact weight used for each of the detectors is unclear. The detector claims an accuracy of 93% based on

testing on a dataset of 100K+ responses .

CheckForAI claims to combine the GPT-2 Output Detector along with custom models to help limit false readings
. The detector also supports account sign up, history storage, and file uploads. The detector provides four classes to

compute the probability of text, as shown in Table 5. This detector is currently limited to 2,500 characters.

CopyLeaks offers products for plagiarism and AI content detection targeted broadly for individuals, educators, and
enterprises. The detector highlights paragraphs written by a human and by AI. CopyLeaks also claims detection across

multiple languages, including Spanish (tested in this paper). CopyLeaks claims an accuracy of 99.12% . The detector

is currently available publicly .

Manuscript submitted to ACM

8

Michael Sheinman Orenstrakh, Oscar Karnalim, Carlos An√≠bal Su√°rez, and Michael Liut

Originality.AI is a detector targeted for content publishers. The detector is available through a commercial sign-up
page  with a minimum fee $20. We received research access for analysis of the detector. The detector comes with

API access and a number of additional features for content creators. A self-proclaimed study by Originality on ChatGPT

suggests that the detector has an accuracy of 98.65% .

We did not impose a systematic approach  to discover publicly available LLM-generated text detectors. Most of

the detectors are recent and cannot be easily found on the internet or academic papers. A systematic approach might

cover fewer results.

3.2 Addressing the RQ: Effectiveness of LLM-generated text detectors

A detector is only worthy of use if it is reasonably effective. We addressed the RQ by comparing detectors listed in Table

2 under three metrics: accuracy, false positives, and resilience. Instructors prefer to use detectors that are reasonably

accurate, reporting a minimal number of false positives, and are resilient to disguises.

Accuracy refers to how effective the detectors are in identifying LLM-generated texts. We present all accuracy results

using two measures of accuracy, as we have found that using only one measure may mislead about some aspect of the

results.

The first method (averages) takes the average prediction each detector across a dataset. As discussed in the discovery

section, each detector either provides a probability that a text is LLM-generated or a category that represents such a

probability. We apply our category to AI conversion tables to obtain a probability for each detector. These probabilities

are averaged for the final results.

The second method (thresholds) is calculated as the proportion of correctly-classified LLM-generated texts. These

are measured as the number of texts that correctly receive above or below a 50% score out of the total number of texts.

This measure is strict, so a prediction of 50% is always considered to be incorrect.

False positives are original submissions that are suspected by LLM-generated text detectors. Fewer false positives are

preferred. For this metric, we collected student submissions before the release of ChatGPT (2019) and measured their

degree of originality with the detectors. Any suspected submissions (originality degree less than 50%) were expected to

be false positives.

Resilience refers to how good LLM-generated text detectors are in removing disguises. Some students might disguise

their LLM-generated texts to avoid getting caught. QuillBot  is a paraphrasing tool capable of paraphrasing text.

The tool uses Artificial Intelligence to reword writing. We paraphrased 10 ChatGPT submissions through QuillBot and

measured the results.

It is worth noting that measuring effectiveness of LLM-generated text detectors is time consuming and labour

intensive. Further, some detectors are not supported with API integration; the authors needed to manually copy and

paste each test case.

3.3 Summarizing our experience using the LLM-generated text detectors

We also report our experience in using the LLM-generated text detectors. Several aspects are considered: intuitiveness,

clarity of documentation, extendability, variety of inputs, quality of reports, number of supported LLM-generated

languages, and pricing.

Manuscript submitted to ACM

Detecting LLM-Generated Text in Computing Education

9

Table 6. Overall accuracy of LLM-generated text detectors measured using thresholds. Sorted from best to worst.

Detectors

Human Data

ChatGPT Data

CopyLeaks
GPT2 Detector
CheckForAI
GLTR
GPTKit
OriginalityAI
AI Text Classifier
GPTZero

99.12%
98.25%
98.25%
82.46%
100.00%
93.86%
94.74%
54.39%

95.00%
95.00%
95.00%
95.00%
75.00%
70.00%
60.00%
45.00%

Table 7. Accuracy of LLM-generated text detectors measured using weighted averages. Sorted from best to worst.

Detectors

CopyLeaks
CheckForAI
GPT2 Detector
GPTKit
AI Text Classifier
OriginalityAI
GLTR
GPTZero

Human
Data

ChatGPT
Data

99.06%
99.12%
97.88%
95.13%
96.49%
86.48%
64.19%
73.95%

94.14%
94.00%
94.70%
69.05%
67.50%
66.77%
67.48%
55.00%

Table 8. False positive readings on LLM-generated text detectors. Sorted from best to worst.

Detectors

GPTKit
CopyLeaks
GPT2 Detector
CheckForAI
AI Text Classifier
OriginalityAI
GLTR
GPTZero

False Positives

0
1
2
2
6
7
20
52

