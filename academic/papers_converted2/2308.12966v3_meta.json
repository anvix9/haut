{
    "language": "English",
    "filetype": "pdf",
    "toc": [
        [
            1,
            "Introduction",
            1
        ],
        [
            1,
            "Methodology",
            3
        ],
        [
            2,
            "Model Architecture",
            3
        ],
        [
            2,
            "Inputs and Outputs",
            4
        ],
        [
            1,
            "Training",
            4
        ],
        [
            2,
            "Pre-training",
            5
        ],
        [
            2,
            "Multi-task Pre-training",
            5
        ],
        [
            2,
            "Supervised Fine-tuning",
            6
        ],
        [
            1,
            "Evaluation",
            6
        ],
        [
            2,
            "Image Caption and General Visual Question Answering",
            6
        ],
        [
            2,
            "Text-oriented Visual Question Answering",
            7
        ],
        [
            2,
            "Refer Expression Comprehension",
            7
        ],
        [
            2,
            "Few-shot Learning on Vision-Language Tasks",
            8
        ],
        [
            2,
            "Instruction Following in Real-world User Behavior",
            8
        ],
        [
            1,
            "Related Work",
            9
        ],
        [
            1,
            "Conclusion and Future Work",
            10
        ],
        [
            1,
            "Dataset details",
            16
        ],
        [
            2,
            "Image-text pairs",
            16
        ],
        [
            2,
            "VQA",
            16
        ],
        [
            2,
            "Grounding",
            16
        ],
        [
            2,
            "OCR",
            16
        ],
        [
            1,
            "Data Format Details of Training",
            18
        ],
        [
            2,
            "Data Format of Multi-Task Pre-training",
            18
        ],
        [
            2,
            "Data Format of Supervised Fine-tuning",
            19
        ],
        [
            1,
            "Hyperparameters",
            19
        ],
        [
            1,
            "Summary of the evaluation benchmarks",
            20
        ],
        [
            1,
            "Additional experimental details",
            20
        ],
        [
            2,
            "Convergence of the Pre-training Stage",
            21
        ],
        [
            2,
            "Number of Learnable Queries in the Vision-Language Adapter",
            21
        ],
        [
            2,
            "Window Attention vs Global Attention for Vision Transformer",
            22
        ],
        [
            2,
            "Performance on Pure-text Tasks",
            23
        ]
    ],
    "pages": 24,
    "ocr_stats": {
        "ocr_pages": 0,
        "ocr_failed": 0,
        "ocr_success": 0
    },
    "block_stats": {
        "header_footer": 0,
        "code": 0,
        "table": 9,
        "equations": {
            "successful_ocr": 0,
            "unsuccessful_ocr": 0,
            "equations": 0
        }
    },
    "postprocess_stats": {
        "edit": {}
    }
}