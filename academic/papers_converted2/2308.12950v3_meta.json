{
    "language": "English",
    "filetype": "pdf",
    "toc": [
        [
            1,
            "Introduction",
            1
        ],
        [
            1,
            "Code Llama: Specializing Llama 2 for code",
            3
        ],
        [
            2,
            "The Code Llama models family",
            3
        ],
        [
            2,
            "Dataset",
            3
        ],
        [
            2,
            "Infilling",
            4
        ],
        [
            2,
            "Long context fine-tuning",
            4
        ],
        [
            2,
            "Instruction fine-tuning",
            4
        ],
        [
            2,
            "Training details",
            5
        ],
        [
            1,
            "Results",
            6
        ],
        [
            2,
            "Code generation",
            7
        ],
        [
            3,
            "Python code generation",
            7
        ],
        [
            3,
            "Multilingual evaluation",
            7
        ],
        [
            2,
            "Infilling evaluations",
            9
        ],
        [
            2,
            "Long context evaluations",
            10
        ],
        [
            2,
            "Ablation studies",
            13
        ],
        [
            3,
            "Fine tuning Llama 2 vs. training from scratch on code",
            13
        ],
        [
            3,
            "Instruction fine-tuning",
            13
        ],
        [
            3,
            "Pass@k evaluation",
            14
        ],
        [
            1,
            "Responsible AI and safety",
            14
        ],
        [
            1,
            "Related work",
            17
        ],
        [
            1,
            "Discussion",
            19
        ],
        [
            1,
            "Acknowledgements",
            26
        ],
        [
            2,
            "Contributions",
            26
        ],
        [
            2,
            "Acknowledgements",
            27
        ],
        [
            1,
            "Code Llama 70B specialization pipeline",
            28
        ],
        [
            1,
            "Additional Ablation Results",
            28
        ],
        [
            1,
            "Math reasoning results",
            29
        ],
        [
            1,
            "Infilling",
            30
        ],
        [
            1,
            "Zero shot results on APPS",
            30
        ],
        [
            1,
            "Long context fine-tuning",
            31
        ],
        [
            2,
            "Further Discussion",
            31
        ],
        [
            2,
            "Long context benchmarks",
            31
        ],
        [
            2,
            "Extended Results",
            33
        ],
        [
            2,
            "Ablations",
            33
        ],
        [
            1,
            "Prompts",
            34
        ],
        [
            2,
            "Self training prompts",
            34
        ],
        [
            2,
            "Evaluation prompts",
            34
        ],
        [
            1,
            "Addition results on responsible AI and safety",
            36
        ],
        [
            1,
            "Examples of red teaming prompts on malicious use of code",
            41
        ],
        [
            1,
            "Model card",
            42
        ],
        [
            1,
            "Qualitative examples",
            43
        ]
    ],
    "pages": 48,
    "ocr_stats": {
        "ocr_pages": 0,
        "ocr_failed": 0,
        "ocr_success": 0
    },
    "block_stats": {
        "header_footer": 0,
        "code": 67,
        "table": 20,
        "equations": {
            "successful_ocr": 1,
            "unsuccessful_ocr": 0,
            "equations": 1
        }
    },
    "postprocess_stats": {
        "edit": {}
    }
}