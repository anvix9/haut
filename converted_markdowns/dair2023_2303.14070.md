<!-- image -->

Review began

06/15/2023

Review ended

06/21/2023

Published

06/24/2023

Â© Copyright

2023

Li et al. This is an open access article distributed under the terms of the Creative Commons Attribution License CC-BY 4.0., which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.

## ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge

Yunxiang Li   , Zihan Li   , Kai Zhang   , Ruilong Dan   , Steve Jiang   , You Zhang 1 2 3 4 1 1

- 1. Department of Radiation Oncology, University of Texas Southwestern Medical Center, Dallas, USA  2. Department of Computer Science, University of Illinois at Urbana-Champaign, Illinois, USA 3. Department of Computer Science and Engineering, The Ohio State University, Columbus, USA 4. College of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, CHN

Corresponding author: You Zhang, you.zhang@utsouthwestern.edu

## Abstract

## Objective

The primary aim of this research was to address the limitations observed in the medical knowledge of prevalent large language models (LLMs) such as ChatGPT, by creating a specialized language model with enhanced accuracy in medical advice.

## Methods

We achieved this by adapting and refining the large language model meta-AI (LLaMA) using a large dataset of 100,000 patient-doctor dialogues sourced from a widely used online medical consultation platform. These conversations were cleaned and anonymized to respect privacy concerns. In addition to the model refinement, we incorporated a self-directed information retrieval mechanism, allowing the model to access and utilize real-time information from online sources like Wikipedia and data from curated offline medical databases.

## Results

The fine-tuning of the model with real-world patient-doctor interactions significantly improved the model's ability to understand patient needs and provide informed advice. By equipping the model with self-directed information retrieval from reliable online and offline sources, we observed substantial improvements in the accuracy of its responses.

## Conclusion

Our proposed ChatDoctor, represents a significant advancement in medical LLMs, demonstrating a significant improvement in understanding patient inquiries and providing accurate advice. Given the high stakes and low error tolerance in the medical field, such enhancements in providing accurate and reliable information are not only beneficial but essential.

Categories: Family/General Practice, Medical Physics, Integrative/Complementary Medicine Keywords: ai chatbot, large language model, llama, chat gpt, gpt

## Introduction

The development of instruction-following large language models (LLMs), such as ChatGPT [1], has gained significant attention due to their remarkable success in instruction understanding and human-like response generation. These auto-regressive LLMs [2] are pre-trained on web-scale natural language by predicting the next token and then fine-tuned to follow large-scale human instructions. These models show robust performance on a wide range of natural language processing (NLP) tasks and can generalize to unseen tasks, demonstrating their potential as unified solutions to various problems in natural language understanding, text generation, and conversational artificial intelligence. However, the exploration of such general-domain LLMs in the medical domain remains relatively scarce [3], despite their great potential in revolutionizing medical communication and decision-making [4]. In general, these common-domain models were not trained to capture the medical-domain knowledge specifically or in detail, resulting in models that often provide incorrect medical responses.

By fine-tuning large linguistic dialogue models on data from real-world patient-physician conversations, these models' ability in understanding patients' inquiries and needs can be significantly improved. In addition, to further enhance the models' credibility, a knowledge brain based on online sources such as Wikipedia or offline sources like medical-domain databases can be incorporated into the models to retrieve real-time information to facilitate answering medical questions. The enhanced reliability of such answers is

vital for the medical field, as a wrong answer can be detrimental to patients' treatments and well-being. In this study, we investigated the use of these two strategies: model fine-tuning and knowledge brain instillation, to enhance the capability of LLMs to serve as medical chatbots. Since the prevalent ChatGPT model is not open source, we used Meta's public large language model meta-AI (LLaMA) model as the platform for development and evaluation. In detail, we first trained a generic conversation model based on LLaMA, using 52K instruction-following data from Stanford University's Alpaca project [5]. We then finetuned the conversation model on our collected dataset of 100K patient-physician conversations from an online medical consultation website (www.healthcaremagic.com). Through extensive experiments, we found that the fine-tuned model by patient-physician dialogues outperforms ChatGPT in terms of precision, recall, and the F1 score [6]. In addition, the autonomous ChatDoctor model, which is able to retrieve the latest online/offline information, can also answer medical questions about relatively new diseases that are not included in the patient-physician training dialogues, for instance, the Monkeypox (Mpox) disease [7,8].

In summary, the ChatDoctor model has the following three main contributions:

- 1. We established a methodology for fine-tuning LLMs for application in the medical field.

2. We compiled and publicly shared a comprehensive dataset of 100,000 patient-doctor interactions to serve as a training resource for refining the LLM. This dataset includes a wealth of terms, knowledge, and expertise essential for training LLMs in the medical domain. Additionally, we curated and openly shared another dataset consisting of 10,000 patient-doctor conversations from a separate source (www.icliniq.com) to serve as a testing resource for the model. To support and stimulate future advancements in the development of dialogue models in healthcare, we provide public access to all relevant resources such as source codes, datasets, and model weights. These can be found at https://github.com/Kent0n-Li/ChatDoctor.

3. We proposed an autonomous ChatDoctor model that can retrieve online and offline medical domain knowledge to answer medical questions on up-to-date medical terms and diseases, which can potentially reduce the errors and hallucinations of LLMs [9-11].

This article was previously posted to the arXiv preprint server on March 24, 2023.

## Materials And Methods

## Collection and preparation of patient-physician conversation dataset

The initial step in refining our model involved curating a dataset comprising patient-physician interactions. Often, patients describe their symptoms in casual and somewhat superficial language. If we attempted to generate these dialogues synthetically, similar to Alpaca [5], it could lead to over-specific descriptions with limited diversity and relevance to the real world. Hence, we chose to gather authentic patient-doctor conversations, collecting around 100k such interactions from the online medical consultation website, HealthCareMagic. The data were filtered both manually and automatically. Specifically, we automatically filtered out conversations that were too short, most of which did not answer anything of practical significance. And we manually filtered the content of the responses that had errors. To maintain privacy, we erased any information identifying the doctor or the patient and employed LanguageTool to rectify any grammatical errors. This dataset was labeled HealthCareMagic100k, illustrated in Figure 1 . We also sourced roughly 10k additional conversations from another independent online medical consultation site, iCliniq, to test our model's performance. The iCliniq dataset was chosen randomly in a stratified manner to guarantee representation across various medical specialties. It was also made certain that the selected data contained no identifiable patient information, in strict compliance with privacy and ethical standards.

FIGURE 1: A summary of the process involved in gathering the patientphysician conversation dataset and the steps involved in training the ChatDoctor model.

<!-- image -->

## Creation of external knowledge database

LLMs typically predict the next word in a sequence, leading to potential inaccuracies or erroneous responses to questions (hallucinations) [12]. In addition, the model's output can be unpredictable to some extent, which is unacceptable in the medical field. However, the accuracy of these models could be significantly improved if they could generate or assess responses based on a reliable knowledge database, depicted in Figure 2 . Consequently, we curated a database (sample shown in Figure 3 ) encompassing diseases, their symptoms, relevant medical tests/treatment procedures, and potential medications. This database serves as an external and offline knowledge brain for ChatDoctor. Continually updatable without requiring model retraining, this database can be tailored to specific diseases or medical specialties. We utilized MedlinePlus to construct this disease database, but other reliable sources can also be used. Additionally, online information sources like Wikipedia can supplement the knowledge base of our autonomous model. It is worth noting that Wikipedia may not be a fully reliable database, but our framework can be easily extended to more reliable online databases such as reputable academic journals.

FIGURE 2: Overview of the autonomous ChatDoctor model based on information retrieval from an external knowledge brain.

<!-- image -->

## Disease Database

Disease: Appendicitis

worse over time. Other symptoms may include: Swelling in the abdomen; Loss of appetite, Nausca and vomiting; Constipation Or diarrhea, Inability to pass gas\_ Low fever gets

Further test: Abdominal Abdominal ultrasound, Blood test to check for signs of infection, Urine test to rule out a urinary tract infection

Treatment: Appendectomy; cefotetan (Cefotan) , cefotaxime (Claforan) , piperacillin and tazobactam (Zosyn) ampicillin and sulbactam (Unasyn) , ceftriaxone (Rocefepime (Maxipime) , gentamicin (Garamycin) , meropenem (Merrem) ertapenem (Invanz) , metronidazole (Cleocin) , levofloxacin (Levaquin). In the case of a ruptured appendix; doctors will prescribe an intravenous (IV) antibiotic to treat abdominal infection.

## Disease: Allergic rhinitis

Further test: Allergy testing, Complete blood count (CBC) testing

Symptoms: Symptoms that occur shortly after you the substance YOu are may develop later include: Stuffy nOSC (nasal congestion) , Coughing; Clogged cars and  decreased sense of smell, Sore throat, Dark circles under the eyes, Fatigue and irritability, Headache:

Treatment: Antihistamines, Antihistamine nasal sprays, Corticosteroids Decongestants

Disease: Malignant otitis externa

Symptoms: Ongoing drainage the Pain may Hearing loss, Itching of the ear from get face

Further test: Look the ear for signs of an outer ear infection. The head around and behind the ear may be tender to touch: A nervous system (neurological) exam may show that the cranial nerves are affected. If there is any drainage, the provider may send the cause of the infection. To look for signs of next to the car canal, the following tests may be done: CT scan of the head, MRI scan of the head, into

Treatment: The of treatment is t0 cure the infection. Treatment often lasts for several months, because it is difficult to treat the bacteria and reach an infection in bone tissue. You will need to take antibiotic medicines for period of time\_ The medicines may be given through or" by mouth Antibiotics should be continued until scans or other tests show the inflammation has gone down. Dead 0r infected tissue may need to be removed from the ear canal. In some cases\_ surgery may be needed to remove dead or damaged tissue in the skull: goal long

FIGURE 3: Some samples in our offline disease database consist of symptoms, clinical test/treatment approaches, and medication suggestions.

## Development of autonomous ChatDoctor with knowledge brain

Armed with the external knowledge brain, i.e., Wikipedia or our custom disease database, ChatDoctor can more accurately answer patient inquiries by retrieving reliable information. Upon establishing the external knowledge brain, we devised a mechanism to enable ChatDoctor to autonomously retrieve necessary information to answer queries. This was accomplished by constructing appropriate prompts to input into the ChatDoctor model. Specifically, we designed keyword mining prompts (Figure 4 ) as the initial step for ChatDoctor to extract key terms from patient queries for relevant knowledge search. Based on these keywords, top-ranked information was retrieved from the knowledge brain using a term-matching retrieval system [13]. Given the LLM's word limit (token size), we divided the texts to be read into equal sections and ranked each section by the number of keyword hits. The ChatDoctor model then reads the first N sections (five used in our study) sequentially, selecting and summarizing pertinent information via prompts (Figure 5 ). Ultimately, the model processes and compiles all the knowledge entries to generate a final response (Figure 6 ). This information retrieval approach ensures patients receive precise, well-informed responses backed by credible sources and can serve as a verification method for responses generated by ChatDoctor

from prior knowledge.

## Prompt for extracting keywords

A question is provided below \_ Given the question, extract keywords from the text. Focus on extracting the keywords that question

{Question of patient}

Keywords:

FIGURE 4: Autonomously extract keywords for information retrieval.

## Prompt for autonomous knowledge retrieval

```
Some information is below. {Relevant content from disease databases or Wikipedia} Response:
```

FIGURE 5: Autonomous information retrieval from the disease database through the prompt.

## Prompt to make a final answer

The original question is as follows: {Question of patient} Based on the information provided:

{Retrieved knowledge}

Answer:

FIGURE 6: Instruct the ChatDoctor to read the retrieved domain knowledge and provide a reliable answer.

## Model training

We developed the ChatDoctor model using Meta's publicly accessible LLaMA-7B model  [14], which uses Transformers with the structure of the decoder only. Despite its relatively modest 7 billion parameters, the LLaMA model exhibits comparable performance to the much larger GPT-3 model (with 175 billion parameters) across several NLP benchmarks. This performance enhancement was achieved by diversifying the training data rather than increasing network parameters. Specifically, LLaMA was trained on 1.0 trillion tokens from publicly accessible data sources like CommonCrawl and arXiv documents. We used conversations from HealthCareMagic-100k to fine-tune the LLaMA model [15] in line with Stanford Alpaca [5] training methodology. The model was first fine-tuned with Alpaca's data to acquire basic conversation skills, followed by further refinement on HealthCareMagic-100k using 6 * A100 GPUs for three hours. The training process followed these hyperparameters: total batch size of 192, learning rate of , 3 epochs, maximum sequence length of 512 tokens, and a warmup ratio of 0.03, with no weight decay.

## Results

To evaluate the proficiency of the autonomous ChatDoctor model, we tested it using a variety of contemporary medical queries. One of these included a question related to 'Monkeypox' (abbreviated as Mpox), as illustrated in Figure 7 . Monkeypox was recently designated by the World Health Organization (WHO) on November 28, 2022, making it a relatively novel term. While ChatGPT was incapable of providing a satisfactory response, ChatDoctor, due to its autonomous knowledge retrieval feature, was able to extract pertinent information about Monkeypox from Wikipedia and deliver a precise answer. Similarly, for more

general medical inquiries such as 'Otitis,' as shown in Figure 8 , ChatDoctor was able to provide a reliable response following the retrieval of relevant knowledge. In another instance, a question about 'Daybue,' a drug that received FDA approval in March 2023, was accurately addressed by our model after it autonomously retrieved relevant information, demonstrating an advantage over ChatGPT, as shown in Figure 9 .

## Example of Mpox

Mpox" Could you please provide more information O context about what you re referring to? This will help me provide you with a more accurate answer .

ChatDoctor: Polymerase chain reaction (PCR) testing of samples from skin lesions is the preferred laboratory test. PCR blood tests are usually inconclusive because the virus remains in the blood for only a short time: To interpret test results; information is required on the date of onset of rash, date of specimen

FIGURE 7: Comparison between the ChatGPT and the autonomous ChatDoctor for relatively new medical diseases/terms. The ChatGPT cannot recognize the word Mpox (aka, Monkeypox), while our ChatDoctor can provide the precise answer for the relevant medical tests of Mpox, with the help of the external knowledge brain.

## Example of Otitis

Q: How to treat Otitis?

ChatGPT: The treatment of otitis depends O the underlying cause and severity of the condition. Treatment may involve antibiotics, car drops, warm compresses, rest, and prevention measures such as avoiding foreign objects in the ear, keeping ears clean and dry; and protecting ears loud noises and sudden It is important to scc a doctor proper  diagnosis and treatment. pain from for

ChatDoctor: Treatment depends on the severity of the symptoms. If there is only mild discomfort, then relievers such as ibuprofen acetaminophen can help. Antibiotics may be prescribed if the infection has spread beyond the outer ear\_ For more serious forms of Otitis, surgery may be needed to remove infected areas of the pain

FIGURE 8: Comparison between the ChatGPT and the autonomous ChatDoctor. The ChatGPT provided a more general answer about otitis, while the ChatDoctor provided a more specialized response about the treatments of otitis, with the help of the external knowledge brain.

## Example of Daybue

Q: What is Daybue used t0 treat?

Daybue. known:  Could you please provide me with morC information\_ such as the correct spelling or the condition it is used to treat?

ChatDoctor: Daybue (trofinetide) is used to treat Rett Syndrome:

FIGURE 9: Comparison between the ChatGPT and the autonomous ChatDoctor. The ChatGPT is unfamiliar with the 'Daybue' medication which received approval from the Food and Drug Administration (FDA) in early 2023. The ChatDoctor accurately pointed out the purpose of Daybue (trofinetide), with the help of the external knowledge brain.

For a quantitative evaluation of ChatDoctor's performance, we utilized questions from the independently sourced iCliniq database as inputs, with the corresponding responses from actual human physicians serving as the benchmark or 'ground truth.' We compared these with responses generated by both ChatDoctor and ChatGPT. In this evaluation, we employed BERTScore [6] to compute Precision, Recall, and F1 scores for both ChatDoctor and ChatGPT. BERTScore leverages pre-trained BERT to match words in the candidate and reference sentences via cosine similarity, and BERTScore was chosen for its ability to evaluate the semantic similarity between our model's responses and the reference sentences, which we believe is of utmost importance in the medical context. This method of evaluation closely aligns with human judgment at both sentence and system levels. In all three metrics, a higher value denotes a better match. As seen in the results illustrated in Table 1 , the fine-tuned ChatDoctor model outperforms ChatGPT across all three metrics, with specific dialogue examples detailed in Figures 10 -13 .

TABLE 1: Quantitative comparison with BERTScore between ChatDoctor and ChatGPT. The pvalues in the table are derived from our paired t-test.

|           | ChatGPT       | ChatDoctor    | P-value   |
|-----------|---------------|---------------|-----------|
| Precision | 0.837Â±0.0188  | 0.8444Â±0.0185 |           |
| Recall    | 0.8445Â±0.0164 | 0.8451Â±0.0157 |           |
| F1 Score  | 0.8406Â±0.0143 | 0.8446Â±0.0138 |           |

## Example 1: ChatGPT vs ChatDoctor\_

Q: Hi doctor,I am getting one-sided headache: I do not get them often: are behind my right eye and temple area. Now this time I am also fighting with heavy cold and cough It came on late morning today and it hurts more when I cough o shake my head or" bend over . Prior to this, I had the same headache about four months ag0. At that time it came On midafternoon and lasted till next morning: Prior to that, had the same headache exactly on the right side and lasted for CCB and Protonix: I am scared of brain tumor\_ Please help. They day:

iCliniq: Hi. Based on what you have told, this is more likely to be due to sinusitis\_ Sinuses are small air filled cavities in your skull bone\_ can infected and when are infected, you will headaches behind eyes. Such headaches will be during cold and cough. Brain tumor headache will be on both sides; more in forchead and you will also have vomiting in that case. Based CT brain and CT paranasal sinuses They get they get

Based on migraine\_ These types of headaches can sometimes be triggered by colds or" other illnesses However it'$ always best to checked out by your doctor to rule out any other u derlying conditions. In terms of a brain tumor; that is a very rare cause of headaches\_ Most people who experience headaches do not have a brain tumor. That being said , if you have any taking over-the-counter pain  relievers such as ibuprofen O acetaminophen to help with the headache: It's also important to plenty of rest and stay hydrated\_ If the headaches persist or become more frequent, please make an appointment with your doctor. Take carel get try get

you that there is no need to worry about the brain tumor Also, we should keep migraine apart as well\_ The most likely cause of your headaches could be sinusitis\_

FIGURE 10: Example 1: a patient suffering from a unilateral headache expressed concerns about a potential association with a brain tumor. Our ChatDoctor accurately proposed sinusitis as a possible cause for the headache, mirroring the diagnosis provided by the physician from iCliniq. On the other hand, ChatGPT failed to deliver a congruent interpretation regarding the root cause of the one-sided headache.

## Example 2: ChatGPT VS ChatDoctor

Q: Hi doctor around the tonsil area in my throat. It has been few months now and the area is swollen. Is this cancer? lump good

Cancer cannot be diagnosed by inspection only. To exclude tonsillar to use a mouthwash and gargle your pharynx then expectorate it many times the for Then if the may have to undergo tonsillectomy: Then examine the tonsillar tissue histologically to detect its nature\_ For more information consult an ENT-otolaryngologist online. Take care. during day

Lam not qualified to provide medical nosis O" advice. However , persistent white lump in the tonsil area that has been present for several months with associated swelling should be evaluated by a medical professional. It could be benign condition such as tonsillar cyst or an inflamed that you seek medical attention from diag-

ChatDoctor: Hi dear , thanks your contact to Chat Doctor\_ some kind of enlarged lymph nodes due to some infective cause like reactive hyperbiopsy should be taken to rule out malignancy: So consult an ENT specialist and examined. Doctor may order blood test, CT scan or ultrasound of neck to confirm Doctor may prescribe antibiotics, anti-inflammatory medications depending upon the cause: Hope this will help you for sure. Contact further if follow up needed\_ Best regards. for having get

FIGURE 11: Example 2: a patient reported having a white lump in their throat for several months and expressed concerns about potential cancer. All three entities, iCliniq, ChatGPT, and ChatDoctor suggested that the patient could be dealing with abnormally enlarged lymph nodes. Both iCliniq and ChatDoctor additionally recommended that a biopsy and radiological diagnosis would be necessary if initial treatments proved unsuccessful. However, ChatGPT's response was limited to advising the patient to consult with an Ear, Nose, and Throat (ENT) specialist.

## Example 3: ChatGPT vs ChatDoctor.

Q: Hi doctor,While working out today; I was doing shoulder press. was it too fast, and at point, I got sharp in my back near where my ribs am also having very sharp pain  when inhaling and care? Currently; [ am taking Zyrtec, Amino acid supplements for energy and muscle recovery; hormonal IUD. doing pain

It looks like you have muscle spasm counter Motrin 600 mg (Ibuprofen twice or thrice with the meal for two to three days and there are topical analgesics available for the gentle massage: It will get better within two to three If it does not relieved, you can see your doctor. Take rest from the shoulder exercise for a week. Get immediate help if feel that this pain is significantly disturbing breathing activity: For more information consult an internal medicine physician online day days get

care for your symptoms. The sharp pain YOu are experiencing when inhaling and exhaling; as well as when rotating your torso O neck; could be sign of a rib important to have an evaluation with healthcare provider to rule out any serious injuries conditions that could require further treatment management. Make sure to inform YOur provider about your current medications and supplements.

ChatDoctor: 1 The symptoms seem to be due to musculoskeletal origin and not related to any organic pathology 2. Muscles of back; chest   wall and abdomen strained vigorous physical activity like weight  training: 3\_ This can cause soreness, stiffness and spasms\_ This is a self 'limiting condition and will subside over few time with adequate rest. 5. You may take anti-inflammatory medications can apply warm compresses over affected areas: 7 . hope this information has been both informative and helpful for you. Wish you get during days good

FIGURE 12: Example 3: a patient reported experiencing a sharp back pain during exercise, which intensified during breathing and rotation of the torso or neck. The patient was unsure whether urgent medical attention was necessary. ChatDoctor generated a closer answer to iCliniq than ChatGPT.

## Example 4: ChatGPT vs ChatDoctor.

Was crystal clear this morning: I just woke up from hour\_ Twice over the years, this has happened, and it normalized ovCr few hours, but I am in jungle now. So, I would like to err on the side of caution\_ I have had previous retinal detachments.

iCliniq: Hello. Did you any surgery done for retinal detachment earlier? It may that may be a cause of this detachment \_ It can also happen in vitreous hemorrhage up. If this is the What is the exact cause can be told only on  examination. You should rush to the emergency asap. If detachment surgery is required then visual prognosis depends on the time elapsed between  episode and surgery. you  should not There is not much can do at the moment by yourself. Just seek help from someone to reach hospital. For more information consult an eye care ophthalmologist online. Take care. get delay:

based sudden change in vision with history of retinal detachments raises concern for possible new detachment o other serious eye condition. It is important that you seek medical attention as soon as possible from an eye specialist. It is better to have it evaluated and treated quickly rather than risking permanent vision loss\_

ChatDoctor: 1) You should see your ophthalmologist for thorough examination and evaluation. 2) There are many causes of sudden loss of vision in one eye; including Or bleeding: 3) Your history of retinal detachment makes me think that there is something wrong with the retina and it needs prompt treatment. 4) This can be treated by laser surgery or if needed, ophthalmologist soon for proper evaluation: prior again our

FIGURE 13: Example 4: a patient experienced blurred vision and was particularly concerned about the health of their left eye. Taking into consideration the patient's past medical history of retinal detachment, all three sources-iCliniq, ChatGPT, and ChatDoctor-advised the individual to seek professional consultation with ophthalmologists for a comprehensive assessment and swift treatment. Due to possible limitations in providing medical diagnoses (and advice), ChatGPT did not speculate on the cause of the diminished vision. On the other hand, both iCliniq and ChatDoctor identified the possibility of retinal detachment or bleeding as potential issues.

## Discussion

The medical LLM, ChatDoctor, which has been fine-tuned on medical data, has extensive potential uses. These range from preliminary patient assessment and automated case adjudication to proactive healthcare measures. Nevertheless, owing to the complex nature of medical information [16], any concealed inaccuracies in diagnoses and health advice could lead to severe outcomes [17]. LLMs are known to occasionally generate fallacious and harmful assertions (hallucinations) about areas beyond their knowledge expertise, potentially causing medical malpractice [18]. To mitigate this, ChatDoctor has been trained using real-world patient-doctor interactions to better understand patients' questions and deliver more knowledgeable responses. To make the model most capable of answering questions about the latest medical terms (which may not be contained in the training dataset), and to introduce additional external references for verification, we also equipped the ChatDoctor model with the ability to autonomously retrieve information from external knowledge brains to provide answers, further enhancing the credibility of the model [19]. Such external knowledge retrieval can be called by inputting pre-configured prompts into the model. In future developments, the internal prior knowledge of the ChatDoctor model (gained through training) and the external knowledge brain can be further combined by training ChatDoctor to select a more trustworthy answer, or merge and fuse both answers or provide alternative opinions.

## Limitations

It is important to emphasize that the current ChatDoctor model is still in the investigation phase and has been developed for academic research only. The actual clinical use is subject to the risk of wrong answers

being output by the model, and the use of exclusively LLMs in medical diagnosis is still plagued by false positives and false negatives for the time being. Additional security measures, including automated reference checking and human expert evaluation, are needed to cross-validate the answers provided by ChatDoctor to flag potentially inaccurate answers and prevent hallucinations. The exact design, development and deployment of such security measures remains an important topic for further research. A more secure application at this stage is the use of LLMs to assist physicians in their face-to-face consultations. Physicians and ChatDoctor work together to ensure not only that the technology is consistent with clinical practice, but also that patient safety is ensured. The evaluation and potential approval of such tools for healthcare-related purposes also needs further investigation.

## Conclusions

With adequate training and online/offline supervision, ChatDoctor can potentially improve accuracy and efficiency in medical diagnosis and reduce the workload for medical professionals. It may also increase access to high-quality medical consultations, especially for patients in underserved regions with limited medical resources. The further developments and applications of ChatDoctor may eventually help to improve patient outcomes and advance medical research.

## Additional Information

## Disclosures

Human subjects: All authors have confirmed that this study did not involve human participants or tissue. Animal subjects: All authors have confirmed that this study did not involve animal subjects or tissue. Conflicts of interest: In compliance with the ICMJE uniform disclosure form, all authors declare the following: Payment/services info: This work was supported by the National Institutes of Health (Grant No. R01 CA240808, R01 CA258987). Financial relationships: All authors have declared that they have no financial relationships at present or within the previous three years with any organizations that might have an interest in the submitted work. Other relationships: All authors have declared that there are no other relationships or activities that could appear to have influenced the submitted work.

## References

- 1. Training language models to follow instructions with human feedback . (2022). Accessed: April 3, 2023: http://arXiv:2203.02155.
- 2. Self-instruct: aligning language model with self generated instructions. (2022). Accessed: December 20, 2022: http://arXiv:2212.10560.
- 3. Aidan Gilson, Conrad W Safranek, Thomas Huang, et al.:  How does chatgpt perform on the united states medical licensing examination? the implications of large language models for medical education and knowledge assessment. JMIR Med Educ. 2023, 9:45312-2023.
- 4. Abacha AB, Zweigenbaum P: Means: a medical question-answering system combining NLP techniques and semantic web technologies. Inf Process Manag. 2015, 51:570-94.
- 5. Stanford alpaca: an instruction-following llama model. (2023). Accessed: April 3, 2023: https://github.com/tatsu-lab/stanford\_alpaca.
- 6. Bertscore: Evaluating text generation with bert. (2020). Accessed: April 21, 2020:  http://arXiv:1904.09675.

7.

Gessain A, Nakoune E, Yazdanpanah Y:  Monkeypox. N Engl J Med. 2022, 387:1783-93.

10.1056/NEJMra2208860

- 8. Beeson AM, Haston J, McCormick DW, Reynolds M, Chatham-Stephens K, McCollum AM, Godfred-Cato S: Mpox in children and adolescents: epidemiology, clinical features, diagnosis, and management . Pediatrics. 2023, 151:e2022060179.
- 9. A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity . (2023). Accessed: February 8, 2023: http://arXiv:2302.04023.
- 10. Selfcheckgpt: zero-resource black-box hallucination detection for generative large language models . (2023). Accessed: March 15, 2023: http://arXiv:2303.08896.
- 11. Salvagno M, Taccone FS, Gerli AG:  Artificial intelligence hallucinations. Crit Care. 2023, 27:180. 10.1186/s13054-023-04473-y
- 12. Beutel G, Geerits E, Kielstein JT:  Artificial hallucination: GPT on LSD?. Crit Care. 2023, 27:148. 10.1186/s13054-023-04425-6
- 13. Retrieval system evaluation. (2005). Accessed: September 26, 2005:

https://www.nist.gov/publications/retrieval-system-evaluation.

- 14. LLaMA: open and efficient foundation language models. (2023). Accessed: February 27, 2023: http://arXiv:2302.13971.
- 15. Raise a child in large language model: towards effective and generalizable fine-tuning . (2021). Accessed: September 13, 2021: http://arXiv:2109.05687.
- 16. Hammerling JA: A review of medical errors in laboratory diagnostics and where we are today . Laboratory Med. 2012, 43:41-4. 10.1309/LM6ER9WJR1IHQAUY
- 17. Lee P, Bubeck S, Petro J: Benefits, limits, and risks of GPT-4 as an AI chatbot for medicine . New England J Med. 2023, 388:1233-9.
- 18. Vaishya R, Misra A, Vaish A:  ChatGPT: is this version good for healthcare and research? . Diabet Metabol Syndr. 2023, 17:102744.
- 19. Hatherley JJ: Limits of trust in medical AI. J Med Ethics. 2020, 46:478-81.  10.1136/medethics-2019-105935