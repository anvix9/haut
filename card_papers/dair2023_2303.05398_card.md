# MathPrompter: Mathematical Reasoning using Large Language Models

# Research questions
Q1: What technique improves Large Language Models (LLMs) performance on arithmetic problems by increasing reliability in predictions?

Contribution: MathPrompter is a novel approach that enhances LLM accuracy on mathematical reasoning tasks by utilizing the Zero-shot chain-of-thought prompting technique, which involves generating multiple algebraic expressions or Python functions to solve a math problem in different ways and verifying their validity.

## Problem Statement, Methods and Main Results
 
  * Introduction of DeepSeek-Coder-Base and DeepSeek-Coder-Instruct, advanced code-focused large language models.
  * Development of repository-level data construction during pre-training for cross-file code generation capabilities.
  * Demonstration of superiority over existing open-source models in various benchmarks.

#### Keywords: Mathematics, Zero-Shot Learning, Chain-of-Thought Prompting, Few-Shot Learning, Natural Language Processing, Arithmetic Reasoning


### [Link to paper](https://arxiv.org/abs/2303.05398)
        