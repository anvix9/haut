# Aligning Text-to-Image Models using Human Feedback

# Research questions
Q1: Can fine-tuning methods learning from human feedback effectively align text-to-image models with their corresponding text prompts?

Contribution: Our method demonstrates that fine-tuning a pre-trained text-to-image model with human feedback significantly improves image-text alignment, achieving up to 47% improvement on human evaluation. 

This research aims to address the problem of aligning generated images with their text prompts in text-to-image synthesis models. The authors identify the challenge that current text-to-image models often fail to generate images well-aligned with text prompts and propose a fine-tuning method using human feedback to improve this alignment. By leveraging human feedback, the proposed method aims to balance the trade-off between image fidelity and alignment.

## Problem Statement, Methods and Main Results
**
* Introduce a fine-tuning method leveraging human feedback for aligning generated images with their corresponding text prompts in text-to-image synthesis models.
* Demonstrate significant improvements in image-text alignment using this novel approach.

#### Keywords: Reward Learning, Fine-Tuning, Human Feedback Alignment, Semi-Supervised Learning, Generative Models, Text-to-Image Synthesis


### [Link to paper](https://arxiv.org/abs/2302.12192)
        