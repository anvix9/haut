# Scaling up GANs for Text-to-Image Synthesis

# Research questions
Q1: Can Generative Adversarial Networks (GANs) be scaled up to benefit from large datasets like LAION, without becoming unstable?

Contribution: We introduce GigaGAN, a new GAN architecture that exceeds the limit of the StyleGAN architecture when scaling up to large datasets.

## Problem Statement, Methods and Main Results
**

* Introducing advanced code-focused large language models (DeepSeek-Coder-Base and DeepSeek-Coder-Instruct).
* Developing repository-level data construction during pre-training for cross-file code generation capabilities.
* Conducting extensive evaluations of the code LLMs against various benchmarks, demonstrating their superiority over existing open-source models.

#### Keywords: Generative Adversarial Networks (GANs), Diffusion Models, Autoregressive Models, Text-to-Image Synthesis, Latent Space Editing


### [Link to paper](https://arxiv.org/abs/2303.05511)
        