# Gemini: A Family of Highly Capable Multimodal Models

        # Research questions
        Q1: Can we develop a multimodal model with strong generalist capabilities across modalities, cutting-edge understanding and reasoning performance in each respective domain, and adapt it to various computational limitations and application requirements for different tasks? 

Contribution: We present Gemini, a family of highly capable multimodal models developed at Google, which is pre-trained jointly across image, audio, video, and text data and post-trained to improve overall quality and enhance target capabilities.

        ## Problem Statement, Methods and Main Results
        **
* Introduction of Gemini, a family of highly capable multimodal models
* Development of advanced code-focused large language models
* Advanced training algorithms, dataset curation, and infrastructure

        #### Keywords: Multimodal Models, Large-Scale Language Modeling, Deep Learning, Neural Networks, Conversational AI, Reinforcement Learning


        ### [Link to paper](https://arxiv.org/abs/2312.11805v4)
        