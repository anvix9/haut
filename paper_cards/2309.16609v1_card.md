# Qwen Technical Report

# Research questions
Here is the research question in clear and concise terms with high precision:

Q1: How do the newly introduced QWEN series of large language models (LLMs) perform on various downstream tasks, such as conversation understanding, code generation, and mathematics problem-solving, compared to existing open-source and proprietary models?

Q2: Can the QWEN LLMs achieve human-like performance on complex tasks, and how do they compare in terms of reproducibility, steerability, and accessibility to service providers?

Q3: What are the implications of making these large language models publicly available, and how will this impact the field of artificial intelligence and related research areas?

Contribution: The QWEN series is designed to provide a comprehensive set of LLMs for various applications, including conversation understanding, code generation, mathematics problem-solving, and vision-language tasks.

## Problem Statement, Methods and Main Results
**
* Comprehensive language model series for various applications
* Showcase of QWEN's capabilities in realistic settings
* Open access approach to foster collaboration and innovation

#### Keywords: Large Language Models, Natural Language Processing, Chatbots, Reinforcement Learning from Human Feedback (RLHF), Human Alignment Techniques, Code Generation, Mathematics-focused models
### [Link to paper](https://arxiv.org/abs/2309.16609v1)
