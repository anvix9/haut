# Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond

# Research questions
Q1: Can vision-language models (LLVs) perceive and understand both visual and textual inputs effectively enough to be used as highly capable assistants in real-world applications?

Contribution: In this work, we introduce the Qwen-VL series of large-scale vision-language models designed to perceive and understand both texts and images.

## Problem Statement, Methods and Main Results
 Qwen-VL series demonstrating superiority over existing vision-language chatbots on real-world dialog benchmarks.

#### Keywords: Vision-Language Models, Large Language Models, Multimodal Understanding, Computer Vision, Natural Language Processing, Reinforcement Learning


### [Link to paper](https://arxiv.org/abs/2308.12966v3)
