# Code Llama: Open Foundation Models for Code

# Research questions
Q1: Can a large language model be trained to generate code and fill in missing parts of code, while taking into account the surrounding context?

Contribution: We release Code Llama , a family of large language models for code generation and infilling derived from Llama 2 (Touvron et al., 2023b) and released under the same custom permissive license.

## Problem Statement, Methods and Main Results

  • Introduced Code Llama, a family of large language models for code generation and infilling.
  • Demonstrated the effectiveness of their approach in handling longer input contexts and providing state-of-the-art results.
  • Provided a solid foundation for future research in this area.

#### Keywords: Natural Language Processing, Code Generation, Programming Languages, Text Classification, Prompt Engineering


### [Link to paper](https://arxiv.org/abs/2308.12950v3)
