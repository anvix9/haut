## Abstract

Partial differential equations (PDEs) are among the most universal and parsimonious descriptions of natural physical laws, capturing a rich variety of phenomenology and multi-scale physics in a compact and symbolic representation. This review will examine several promising avenues of PDE research that are being advanced by machine learning, including: 1) the discovery of new governing PDEs and coarse-grained approximations for complex natural and engineered systems, 2) learning effective coordinate systems and reduced-order models to make PDEs more amenable to analysis, and 3) representing solution operators and improving traditional numerical algorithms. In each of these fields, we summarize key advances, ongoing challenges, and opportunities for further development.

## 1 Introduction

Partial differential equations (PDEs) have been a cornerstone of mathematical physics and engineering design for over 250 years, since the introduction of the one-dimensional wave equation by d'Alembert in 1752 [20]. PDEs provide a formal mathematical infrastructure for relating how quantities of interest change in several variables, typically space and time. As such, PDEs provide a foundational description of the governing equations of many canonical spatio-temporal physical systems, including electrodynamics, quantum mechanics, fluid mechanics, heat transfer, etc. Today, nearly every aspect of our engineered world is based in some way on the predictive capability of PDEs, from structural modeling of buildings and bridges, to the design of aircraft and other vehicles, to the thermal and electromagnetic management systems in modern portable electronics. In general, we will consider a PDE for u ( x, t )

u t + N ( u, u x , u xx , · · · , x, t ; µ ) = f ( x ) (1)

on a spatial domain x ∈ [0 , L ] ,for time t ∈ [0 , T ] , and where the parameter µ denotes a parametric dependency. The initial and boundary conditions are given by

IC: u ( x, 0) = u 0 ( x ) (2a)

BC: α 1 u (0 , t ) + β 1 u x (0 , t ) = g 1 ( t ) and α 2 u ( L, t ) + β 2 u x ( L, t ) = g 2 ( t ) . (2b)

This may be generalized to systems of several spatial variables, or a system with no time dependence.

In the past half-century, the advent of computing has produced two revolutions in our capability to analyze and solve PDEs. In the first, closed-form analytic solution techniques, which typically rely on linearity and superposition principles, have given way to diverse computational approximations based upon finite difference, finite element, and spectral techniques. These computational approaches significantly expand the complexity of behaviors and solutions that can be analyzed. Importantly, scientific computing has allowed for the study of nonlinear systems for which our analytic techniques typically fail. Additionally, complex boundary conditions, difficult geometries, and multiscale interactions can all be characterized within this framework. Thus, the combination of analytic and computational methods for solving PDEs has driven critical technological advancements in many industries since the 1960s. However, modern PDE systems are often nonlinear, complex, and high-dimensional, rendering analytic techniques ineffective and computational methods intractable. More recently, the ongoing machine learning revolution is providing an entirely new approach for solving PDEs, based on the increasing wealth of high-quality data generated from both simulations and experiments. Indeed, the emergence of machine learning methods in the last decade have allowed the community a significantly different approach to modeling the dynamics of PDEs, allowing for the learning and construction of proxy, reduced-order models which are faithful representations of the full, high-dimensional complex dynamics. Although machine learning has been applied to study PDEs for nearly three decades [47], several key advances in computational capabilities and algorithms are dramatically accelerating these efforts in the past decade.

In this review, we explore several avenues of PDE research that are being advanced by machine learning:

- · Governing equations and coarse-grained closures: Emerging techniques in symbolic regression and new high-fidelity measurements are making it possible to learn new PDEs for systems that are not amenable to first-principles and by-hand derivations. Systems in neuroscience and epidemiology, as well as systems from traditional physics, such as plasma dynamics, non-Newtonian fluids, and active matter, are all candidates for improved PDE descriptions. Moreover, there are many systems where we have accurate governing equations, but they are too computationally expensive to resolve at all scales of the physics. Thus, one must resort to coarse-grained PDEs. Machine learning is enabling tremendous progress in this traditionally challenging field, for example in turbulence modeling and the modeling of geophysical fluids. Several other fields stand to benefit, including material science and biology.
- · Coordinate systems and reduced representations: Solution techniques for PDEs are intimately tied to a coordinate system. For example, the Fourier transform is the coordinate system that diagonalized Laplace's equation. However, for nonlinear PDEs there is generically no coordinate system that simplify the equations. Advances in modern Koopman operator theory are providing a powerful new perspective for finding effective coordinates even for nonlinear systems. Similarly, reduced-order models provide a reduction of a PDE to a much simpler ODE system that is tailored to the specific configuration and parameters of interest. Machine learning has rapidly been adopted as a new technique for ROMs, as it shares a significant overlap and history with this field of applied mathematics. For many iterative design optimization and control applications, ROMs are critical, as there is a tradeoff between the accuracy of a solution and the cost of computing it.
- · Numerical solutions and operator learning: Another major avenue of research is focused on learning the solution operator of complex PDEs, trained from limited amounts of high-fidelity data. These approaches are quite flexible and offer many advantages, including the ability to re-mesh solutions flexibly. In related work, researchers are currently using machine learning to improve traditional scientific computing workflows, for example to improve pre-conditioning and to learn improved stencils for shocks and discontinuities.

Our goal with this review is to provide a brief summary and organization of the rapid progress in this field, along with a high-level perspective on the ongoing challenges and avenues of future opportunity. Although machine learning is changing how we learn, represent, and solve PDEs, many things haven't changed. We still seek interpretable and generalizable representations of the governing equations and their solutions. We still use techniques from scientific computing to integrate many of these models and propagate their uncertainty. And we still use the same iterative design optimization and control algorithms, now wrapped around machine learned models and solutions. The importance of embedding physics into machine learning has also become increasingly clear in recent years [17-19, 21, 23, 39, 42, 67, 82, 133, 134]. Incorporating physics into the learning process makes it possible to achieve more accurate solutions, with more compact architectures, and from less and noisier training data.

## Operator learning and kernel methods

In the original paper advocating the construction of Neural Operators , the Green's function representation of the solution motivates the proposed mappings between function spaces, thus allowing for the approximation of operators N ( · ) which encode governing equations and physics [71, 76-78]. Thus neural operators leverage integral kernel representation in their approximation of the operator. For instance, neural operators can make explicit use of multi-pole [77] and Fourier [76] kernels in order to construct operator representations. Thus nonlocal representations of the solution are parametrized by the integral operator. Recall that learning a nonlinear operator G ( · ) will be equivalent to learning the inverse of the PDE evolution (1). Thus kernel operators are intuitively appealing for the construction of the nonlinear operator based upon their connection to the linear kernel inversion (11). The overall representation of the operator is a trained neural network G = f θ where individual layers of the neural network are constructed from a learned integral representations that are updated according to the following kernel-based representation

v k +1 ( x ) = σ k +1 ( W t v k + ∫ D k K ( k ) ( x, y ) v k ( y ) dν k ( y ) + b k ( x ) ) (13)

where ν k is a Lebesgue measure on R d t . The kernel K ( k ) ( x, y ) is typically chosen to leverage advantageous representations, such as the multi-pole or Fourier kernels. Thus each layer of the network is trained using a physics-inspired concept of an integral (inverse) representation of the PDE dynamics. Thus instead of constructing a Green's function kernel, which can technically only be done with a linear operator L , the kernel representation is used to train a

Figure 4: Zero-shot super-resolution: Vorticity field of the solution to the two-dimensional Navier-Stokes equation with viscosity 10 4 ( Re = O (200) ); Ground truth on top and prediction on bottom. The model is trained on data that is discretized on a uniform 64 × 64 spatial grid and on a 20-point uniform temporal grid. The model is evaluated with a different initial condition that is discretized on a uniform 256 × 256 spatial grid and a 80-point uniform temporal grid ( From Kovachki et al [71] ).

<!-- image -->

representation of the inverse operator N -1 ( · ) . Rigorous estimates of the convergence rates and computational costs for learning such linear operators can now be derived rigorously [43, 44, 97].

More broadly, neural operators generalize standard feed-forward neural networks to learn mappings between infinite-dimensional spaces of functions defined on bounded domains of R d . The non-local component of the architecture is instantiated through either a parameterized integral operator or through multiplication in the spectral domain (which is a specific form of the kernel in the integral operator). Once trained, neural operators have the property of being discretization invariant: sharing the same network parameters between different discretizations of the underlying functional data. Thus it is a mesh free method, as shown in Fig. 4 on the Navier-Stokes equation.

Onamorefoundational level, Chen and Chen [35] developed a proof that neural networks with a single hidden layer can approximate accurately any nonlinear continuous operator. Thus a nonlinear operator is learned mapping from functions to functions. In practice, this is a highly impactful theory as it provides guarantees on the construction of an operator which contains information about the physics and dynamics of the system. The theorem of Chen and Chen is the basis of the DeepOnet method of Lu et al [86, 87] ( DeepOnet ) as well as the neural operators of Kovachki et al [71]. The original work of Chen and Chen [35] construct a universal approximation proof. The theorem provides a theoretical bounds on the ability of a neural network to approximate the operator G ( · ) . It also highlights the construction of two neural networks so that it can be more compactly represented as

∣ ∣ ∣ G ( u )( y ) -f θ 1 ( u ) · ˜ f θ 2 ( y ) ∣ ∣ ∣ < glyph[epsilon1] (14)

when considering the discretized representation of u ( x ) → u and new measurement (function evaluation) locations y → y . The two simultaneously trained networks are the branch network f θ 1 ( u ) and the trunk network ˜ f θ 2 ( y ) .

Mathematically, the concept is quite simple. Given a number of measurement (sensor) locations x k (usually selected from a computational grid) which prescribes the input function u k = u ( x k ) , a vector of training input data can be constructed u . The input data has a corresponding output data G ( u ) . In addition, training data mapping selections of random measurement points y to the output G ( u ( y ) is required. Thus the input functions u are encoded in a separate network than the location variables y . These are merged at the end as shown in the universal approximation proof of Chen and Chen [35]. Figure 5 shows the results of training from the original DeepOnet paper of Lu et al [76, 86, 87] on reaction-diffusion system. DeepOnets also can achieve small generalization errors by employing inductive biases. Remarkably, exponential convergence is observed in the deep learning algorithm.

So although both neural operators and DeepOnets accomplish the same goal, they do so with significantly different architectures. Neural operators exploit the kernel structure of generic operators while DeepOnets train by separating the input function from the spatial locations. Both have achieved promising results, highlighting the fact that the learning of operators can potentially allow for mesh-free models of physics systems. Of course, in order for this to actually be viable in practice, exceptional training data that resolves all scales should be employed in training. Figure 4 highlights the results from Kovachki et al [71] where neural operators are used to model fluid flows.

Figure 5: Learning a reaction-diffusion with DeepOnet. (A) (left) An example of a random sample of the input function u ( x ) . (middle) The corresponding output function s ( x, t ) at P different ( x, t ) locations. (right) Pairing of inputs and outputs at the training data points. The total number of training data points is the product of P times the number of samples of u . (B) Training error (blue) and test error (red) for different values of the number of random points P when 100 random u samples are used. (C) Training error (blue) and test error (red) for different number of u samples when P = 100 . The shaded regions denote one-standard-derivation ( From Lu et al [86] ).

<!-- image -->

## For d spatial dimensions there are 5 Discussion

direction.

to fit closures to classical turbulence models based on agreement with high-resolution DNSs (21-24). While potentially more accurate than traditional turbulence models, these new models have not achieved reduced computational expense. Another major thrust uses 'pure' ML, aiming to replace the entire Naviermuch faster than pure numerical simulations due to the reduced grid size. In this work we design algorithms that accurately solve the equations on coarser grids by replacing the components most affected by the resolution loss with better-performing learned In this perspective, we have explored how emerging techniques in machine learning are enabling major advances in the field of partial differential equations. In particular, we have summarized efforts to 1) discover new PDEs and coarse-grained closure models from data, 2) to uncover new coordinate systems in which the PDE and its solution become simpler, and 3) to directly learn solution operators and other techniques to accelerate numerics. In every case, despite significant progress, there are several ongoing challenges and opportunities for development.

Stokes simulation with approximations based on deep neural networks (25-30). A pure ML approach can be extremely efficient, avoiding the severe time-step constraints required for stability with traditional approaches. Because these models do not include the underlying physics, they often cannot enforce hard constraints, such as conservation of momentum and incompressibility. While these models often perform well on data from the training distribution, they often struggle with generalization. For example, they perform worse when exposed to novel forcing terms. We believe 'hybrid' approaches that combine the best of MLand traditional numerical methods are more promising. For example, ML can replace (31) or accelerate (32) iterative solves used inside some simulation methods without reducing accuracy. alternatives. We use data-driven discretizations (36, 37) to interpolate differential operators onto a coarse mesh with high accuracy (Fig. 1 C ). We train the model inside a standard numerical method for solving the underlying PDEs as a differentiable program, with the neural networks and the numerical method written in a framework [JAX (38)] supporting reverse-mode automatic differentiation. This allows for end-to-end gradientbased optimization of the entire algorithm, similar to prior work on density functional theory (39), molecular dynamics (40), and fluids (33, 34). The methods we derive are equation-specific and require high-resolution ground-truth simulations for training data. Since the dynamics of a PDE are local, the high-resolution simulations can be carried out on a small domain. The models In the field of discovery and coarse-graining, there are several avenues of ongoing research. Preliminary results show that it is possible to learn new physical mechanisms and closure models, mainly in fluid systems. There is a tremendous opportunity to refine and leverage these new closure models to accelerate simulations of turbulent fluid systems to enable their use in a diverse range of applications and technologies. Moreover, there are many new fields where this approach might be applied: neuroscience, epidemiology, active matter, non-Newtonian fluids, among others. In addition, there is an opportunity to incorporate partial knowledge of the physics, including symmetries and invariances. The dual of this, is that given a new discovered PDE, it may be possible to relate this to a new conservation or invariance. In any of these situations, when a PDE is uncovered, it is possible to automatically cluster the dynamics in space and time by what terms in the PDE are in a dominant balance with eachother. Similarly, it may be possible to identify the controlling nondimensional parameters that determine the bifurcation structure of the system.

Here we focus on hybrid models that use ML to correct errors in cheap, underresolved simulations (33-35). These models borrow strength from the coarse-grained simulations and are potentially remain stable during long simulations and have robust and predictable generalization properties, with models trained on small domains producing accurate simulations on larger domains, with Even when a PDE is known, from first principles or from data-driven learning algorithms, the presence of nonlinearity makes it so that there are no generic solution techniques. We have seen that advances in Koopman operator theory are making it possible to learn new coordinate systems in which nonlinear systems become linear.

2 of 8

|

PNAS

https://doi.org/10.1073/pnas.2101784118

Kochkov et al.

Machine learning-accelerated computational fluid dynamics

Fig. 1.

<!-- image -->

<!-- image -->

Forced turbulence

Generalization tests

<!-- image -->

<!-- image -->

Larger domain

<!-- image -->

More turbulent

Decaying

<!-- image -->

For example, the Cole-Hopf transformation may be seen as a Koopman coordinate transformation in which case the nonlinear Burgers' equation maps into the linear heat equation. There are many opportunities to discovery similar coordinate transformations for more complex systems, such as the Navier-Stokes equations. In addition to learning linearizing transformations, it may be possible to relax this stringent constraint, and instead learn transformations into a coordinate system where the dynamics are simplified, with asymptotic or perturbative nonlinearities. This is related to normal form theory, where it may be possible to dramatically simplify the dynamics with a much less complex coordinate transfomrmation.

Finally, there are several efforts underway to accelerate numerics associated with solving PDEs, as well as to approximate the solution operators directly. The universal approximation capabilities of neural networks make them particularly useful for representing the solutions to PDEs, which may be arbitrarily complex. Understanding how these solution operators vary with system parameters is an important avenue of ongoing research [102]. Similarly, machine learning may be used to accelerate traditional scientific computing workflows, for example by flexible super-resolution or learning of improved solution stencils. However, here are several challenges with these approaches, foremost the fact that traditional numerical algorithms are extremely mature and scaleable, so that machine learning solutions are expected to compete with decades of progress.

In all of the cases explored in this perspective, progress will be accelerated by a diverse and robust set of benchmark problems with which to assess new solutions [130]. In addition, we must stress that these techniques are primarily tools to be used by human experts for scientific discovery. In the past, many advances have been driven in the field of fluid mechanics [23], and this is likely to continue. For example, understanding sensitivities with resolvent analysis [123], using physics informed neural networks (PINNs) [109] for RANS modeling [50], and using wall measurements to estimate turbulent flow fields [59] are all exciting avenues of research. Interestingly, there are also efforts to understand neural networks using techniques from PDEs [27].

Although there is a desire for automated machine learning algorithms, when applied to science and engineering applications, this is still primarily a human endeavor. However, progress in the field of PDEs, enabled by machine learning, is undeniable. Despite this progress, there is still much we don't know about PDEs. For example, it is unknown whether or not all solutions of the incompressible fluid flow equations even remain bounded in finite time, making it one of the 'Millennium Prize' problems. Our limitations in our understanding of PDEs is nicely summarized by Richard Feynman [52]:

'The next great era of awakening of human intellect may well produce a method of understanding the qualitative content of equations. Today we cannot. Today we cannot see that the water flow equations contain such things as the barber pole structure of turbulence that one sees between rotating cylinders. Today we cannot see whether Schrodinger's equation contains frogs, musical composers, or morality-or whether it does not. We cannot say whether something beyond it like God is needed, or not. And so we can all hold strong opinions either way.'

