## Abstract

Transfer learning has recently become the dominant paradigm of machine learning. Pretrained models fine-tuned for downstream tasks achieve better performance with fewer labelled examples. Nonetheless, it remains unclear how to develop models that specialise towards multiple tasks without incurring negative interference and that generalise systematically to non-identically distributed tasks. Modular deep learning has emerged as a promising solution to these challenges. In this framework, units of computation are often implemented as autonomous parameter-efficient modules. Information is conditionally routed to a subset of modules and subsequently aggregated. These properties enable positive transfer and systematic generalisation by separating computation from routing and updating modules locally. We offer a survey of modular architectures, providing a unified view over several threads of research that evolved independently in the scientific literature. Moreover, we explore various additional purposes of modularity, including scaling language models, causal inference and discovery, programme simulation, and hierarchical reinforcement learning. Finally, we report various concrete applications where modularity has been successfully deployed such as cross-lingual and cross-modal knowledge transfer.

Table of Contents

|   1 | Introduction and Motivation                                                                                                    |   3 |
|-----|--------------------------------------------------------------------------------------------------------------------------------|-----|
| 2   | Modular Deep Learning                                                                                                          |   6 |
| 2.1 | Taxonomy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   |   6 |
| 2.2 | Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . |   6 |
| 3   | Computation Function                                                                                                           |   8 |
| 3.1 | Parameter Composition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .      |   8 |
| 3.2 | Input Composition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    |  12 |
| 3.3 | Function Composition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .     |  12 |
| 3.4 | Hypernetworks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    |  15 |

| 3.5 Unifying Parameter, Input, and Function Composition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .         | 3.5 Unifying Parameter, Input, and Function Composition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .         | 3.5 Unifying Parameter, Input, and Function Composition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .              | 15   |
|-----------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|------|
| Routing Function                                                                                                                  | Routing Function                                                                                                                  | Routing Function                                                                                                                       | 16   |
| 4.1 Fixed Routing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . | 4.1 Fixed Routing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . | 4.1 Fixed Routing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .      | 17   |
| 4.2                                                                                                                               | Learned Routing                                                                                                                   | . . . . . . . . . . . . . . . . . .                                                                                                    | 19   |
|                                                                                                                                   | 4.2.1 Challenges of Learned Routing                                                                                               | . . . . . .                                                                                                                            | 19   |
|                                                                                                                                   | 4.2.2                                                                                                                             | Hard Learned Routing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                     | 19   |
|                                                                                                                                   | 4.2.3                                                                                                                             | Soft Learned Routing . . . . . . . . . . .                                                                                             | 21   |
|                                                                                                                                   | 4.2.4                                                                                                                             | Hypernetworks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                    | 23   |
| 4.3 Level of Routing                                                                                                              | 4.3 Level of Routing                                                                                                              | . . . . . . . . . . . . . . . . . .                                                                                                    | 23   |
| Aggregation Function                                                                                                              | Aggregation Function                                                                                                              | Aggregation Function                                                                                                                   | 24   |
| 5.1                                                                                                                               | Parameter Aggregation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .       | Parameter Aggregation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .            | 24   |
| 5.2                                                                                                                               |                                                                                                                                   | Representation Aggregation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .             | 25   |
|                                                                                                                                   | 5.3                                                                                                                               | Input Aggregation . . . . . . . . . . . . . . . . .                                                                                    | 26   |
| 5.4                                                                                                                               |                                                                                                                                   | Function Aggregation . . . . . . . . . . . . . . .                                                                                     | 27   |
| 6 Training Setting                                                                                                                | 6 Training Setting                                                                                                                | 6 Training Setting                                                                                                                     | 28   |
| 6.1                                                                                                                               | Joint Multitask Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .      | Joint Multitask Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .           | 28   |
| 6.2                                                                                                                               |                                                                                                                                   | Continual Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .           | 29   |
| 6.3                                                                                                                               | Parameter-efficient Transfer Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .       | Parameter-efficient Transfer Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .            |      |
| 7 Applications in Transfer Learning                                                                                               | 7 Applications in Transfer Learning                                                                                               | 7 Applications in Transfer Learning                                                                                                    | 30   |
| 7.1                                                                                                                               |                                                                                                                                   | Parameter-Efficient Fine-tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .            | 30   |
|                                                                                                                                   | 7.1.1                                                                                                                             | Machine Translation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                    | 30   |
|                                                                                                                                   | 7.1.2                                                                                                                             | Cross-Lingual Transfer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Domain Adaptation | 31   |
|                                                                                                                                   | 7.1.3                                                                                                                             | . . . . . . . . . . . .                                                                                                                | 33   |
|                                                                                                                                   | 7.1.4                                                                                                                             | Knowledge Injection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                    | 33   |
|                                                                                                                                   |                                                                                                                                   | Computer Vision and Cross-Modal Learning                                                                                               | 34   |
|                                                                                                                                   | 7.1.6 7.1.7                                                                                                                       | Comparison and Design Principles . . . .                                                                                               | 35   |
| 7.2                                                                                                                               | Task Generalisation . . .                                                                                                         | . . . . . . . . . . . . .                                                                                                              | 36   |
|                                                                                                                                   | Other Purposes of Modularity                                                                                                      |                                                                                                                                        | 36   |
| 8.1                                                                                                                               | Hierarchical Reinforcement Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .         | Hierarchical Reinforcement Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .              | 37   |
| 8.2                                                                                                                               | Programme Simulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .        | Programme Simulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .             | 38   |
| 8.3                                                                                                                               | Causal Discovery and Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .        | Causal Discovery and Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .             | 40   |
| Conclusions                                                                                                                       | Conclusions                                                                                                                       | Conclusions                                                                                                                            | 42   |
| 9.1                                                                                                                               | Future Work .                                                                                                                     | . . . . . . . . . . . . . . . . . . .                                                                                                  | 43   |
|                                                                                                                                   | Modular Instruction Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                | Modular Instruction Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                     | 43   |

## 1 Introduction and Motivation

Transfer learning has recently become pervasive in machine learning technology, such as in natural language processing (Ruder et al., 2019b; Brown et al., 2020), computer vision (Dosovitskiy et al., 2021), and reinforcement learning (Reed et al., 2022), among other areas. In its most successful incarnation, transfer learning consists of pre-training a model on vast amounts of raw data in a self-supervised fashion and subsequently fine-tuning it for new tasks based on a small number of labelled examples. Despite its success, this paradigm for transfer learning suffers from a series of limitations in various settings. Firstly, in multi-task fine-tuning, the learning signals from different tasks may negatively interfere with each other (McCloskey & Cohen, 1989). Similarly, in continuous learning, adapting to new examples can result in catastrophic forgetting of knowledge acquired from previous examples (Sutton, 1986; French, 1999). 1 Secondly, in settings where the training and evaluation distributions are not identical, these models fail in generalising systematically (Lake & Baroni, 2018; Hupkes et al., 2020). This makes models brittle and inaccurate and hampers their deployment in real-world applications, where distribution shifts are common.

In contrast, many biological and artificial systems do not suffer from these weaknesses by virtue of their modularity (Fodor, 1983; Ballard, 1986), defined as the correspondence between strongly interconnected components of a system (i.e., modules) and the functions they perform (Baldwin & Clark, 2000; Ulrich, 1995). In other words, each module is specialised for a unique purpose, for which it is reused consistently. In animal brains, this favours evolvability , the ability to adapt quickly to new environments, and resilience to environment perturbations (Wagner et al., 2005) because it makes rewiring connections easier than in monolithic, entangled networks (Kashtan & Alon, 2005). Artificial systems, such as programming languages and computer hardware, are similarly designed in a modular fashion (Booch et al., 2008; Baldwin & Clark, 2000) because this modular design favours consistency, ease of adaptation, and interpretability.

To what extent, then, do 'vanilla' neural networks display the desirable property of being modular? In principle, given their fully connected nature, they could develop such a structure as a by-product of optimising a loss for a downstream task. Recent structural analyses based on hierarchical clustering of neurons revealed that vanilla neural networks can indeed learn such a modular pattern (Watanabe, 2019; Casper et al., 2022; Foroutan et al., 2022). Favourable conditions for the emergence of modularity include multi-task learning (Dobs et al., 2022) and regularisation through dropout (Lange et al., 2022). In particular, from a structural perspective, populations of neurons may activate jointly in response to specific features of the input or the output classes 2 , resulting in similar changes in model performance when ablated (Meyes et al., 2020). From a functional perspective, multi-task learning may lead to segregated, specialised sub-networks (Yang et al., 2019; Dobs et al., 2022). On the other hand, Csordás et al. (2021) revealed that a given sub-network does not tend to be re-used for similar sub-tasks nor to be combined with others to express more complex functions. In fact, in many cases, the performance of a model on simple tasks requiring a certain skill and composite tasks requiring a combination thereof is entirely uncorrelated (Li et al., 2022a).

For this reason, previous work explored the idea of designing neural networks that are explicitly modular (Jacobs et al., 1991a; Rosenbaum et al., 2018; Ponti, 2021; Mittal et al., 2022). This has the goal of achieving not only functional specialisation (Zhang et al., 2022b), but also re-usability and composability . In particular, these methods involve identifying 1) modules in a neural network that can be updated locally and asynchronously, without affecting the rest of the parameters; 2) a routing function that chooses a subset of modules for each example or task; and 3) an aggregation function that aggregates the outputs of the active modules. Each of these three ingredients can be manually specified or learned. We provide several case studies of different configurations of these components in Figure 1.

The main advantages of modular neural architectures are positive transfer , compositionality , and parameter efficiency . Firstly, modularity encourages positive transfer by encoding similar functions with the same module. At the same time, it prevents interference and forgetting by allocating distinct functions to different dedicated modules (Jacobs et al., 1991b). For instance, massively multilingual Transformer-based models in NLP are

Figure 1: Case studies of modular deep learning; best viewed in colour. Green components illustrate different routing functions (see § 4); shade-of-purple components illustrate modular computation functions (see §3). 1a) MAD-X (Pfeiffer et al., 2020b) uses Adapter layers with fixed routing for zero-shot cross-lingual transfer. 1b) Polytropon (Ponti et al., 2022) uses low-rank adapters (LoRA; Hu et al., 2022) with hard learned routing for few-shot task adaptation. 1c) MoE Transformers (Fedus et al., 2021; Clark et al., 2022, inter alia ) use Multi-Layer Perceptrons with topk soft routing, in order to scale to larger model sizes. The three representative models illustrated here are only a fraction of possible configurations from the 'configuration manifold' that can be created by varying the components surveyed in §3-§6.

<!-- image -->

known to suffer from a 'curse of multilinguality' (Conneau et al., 2020) due to the conflicting information that the gradient from each language-specific loss carries (Wang et al., 2021b). A possible solution is augmenting these entangled, fully shared models with specialised modules responsible for individual languages (Pfeiffer et al., 2020b; 2022b). More generally, as the range of tasks modelled jointly by a single model becomes increasingly diverse, modularity may be instrumental in the advent of general-purpose, multi-modal agents that encompass vision, language, and action (Reed et al., 2022).

Secondly, modules representing different skills (at the task level) or features (at the example level) can be composed together and updated locally, without affecting the rest of the network. These two properties are crucial in two main settings, which correspond to different aspects of systematic generalisation : one is the ability to re-compose , i.e. zero-shot transfer to tasks consisting of new combinations of learned skills, or examples consisting of new combinations of observed features (Hupkes et al., 2020). For instance, while modules for the Guaraní language and for dependency parsing can only be trained separately due to the lack of annotated data for dependency parsing in Guaraní, they can be composed to perform inference on this unobserved task-language combination (Pfeiffer et al., 2020b). Similarly, in hierarchical reinforcement learning, an agent can follow different sequences of modular policies known as options in tasks requiring the completion of similar sub-goals in different orders (Sutton et al., 1999; Precup, 2000). The other aspect of systematic generalisation is robustness . In fact, if modules are taken to correspond to independent and reusable physical mechanisms (Schölkopf et al., 2012), local shifts in their distributions require updating only the parameters accounting for the affected skills or features (Goyal et al., 2021; Schölkopf et al., 2021), while the rest of the model remains invariant to the change. In practice, the ability to perform local updates facilitates sample efficiency, as fewer examples are necessary to adapt models to new tasks (Bengio et al., 2020; Ponti et al., 2022).

Thirdly, an additional advantage of modular neural architectures is parameter and time efficiency . In this framework, fine-tuning a model on a specific task only requires storing a modular adapter rather than a separate copy of the entire (typically large) model. What is more, modules can be added or removed on-the-fly in an incremental manner, adjusting the model capacity according to the task complexity. This ability is known as conditional computation (Bengio et al., 2015). Finally, modularity enables language models to scale to larger numbers of parameters while retaining the same time complexity, by selecting only a small set of experts per example (Shazeer et al., 2017; Fedus et al., 2021).

As the main contribution of this survey, we offer a unified view of modular deep learning, illustrating how many families of methods can be defined along four key dimensions: 1) how they implement modules, which constitute the minimum unit of computation; 2) how they select active modules through a routing function; 3) how module outputs are aggregated; and 4) how the modules are trained with the rest of the model.

For module implementation, we discuss sparse subnetworks (Hu et al., 2022; Ansell et al., 2022), adapter layers (Rebuffi et al., 2018; Pfeiffer et al., 2020b), and prefix tuning (Li & Liang, 2021), among others. These methods have been proven as an effective way to adapt large pre-trained models, achieving better performance and sample efficiency than alternative strategies such as in-context learning (Liu et al., 2022b), which may be brittle (Lu et al., 2022). In fact, modules can also take the form of human-engineered prompts, where the model is provided with input-output examples (Brown et al., 2020) or task instructions (Wei et al., 2022a). While many module implementations share the same underlying functional form (He et al., 2021), they offer different trade-offs between efficiency and performance.

We then discuss how routing functions control the flow of information to the modules: in fixed routing, module allocation is manually defined when expert knowledge is available(Hampshire & Waibel, 1992; Rajendran et al., 2017, inter alia ). In learned routing, a parameterised routing function is inferred during training. This, however, poses a series of challenges, such as training instability, module collapse, and overfitting (Rosenbaum et al., 2019). Orthogonally, we also distinguish between hard and soft routing. In hard routing, only a subset of modules is activated (Rosenbaum et al., 2018; Ponti et al., 2022; Fernando et al., 2017, inter alia ). In soft routing, all modules are aggregated according to continuous scores (Jacobs et al., 1991b; Jordan & Jacobs, 1994). While soft routing is amenable to vanilla gradient descent, it is highly inefficient. On the other hand, hard routing requires approximate inference but facilitates conditional computation and module specialisation. When multiple modules are selected, several aggregation strategies are possible. For instance, these can be based on interpolating the parameters of active modules (Ansell et al., 2022) or an attention mechanism over the module outputs (Pfeiffer et al., 2021a). Alternative methods include input prompt concatenation (Vu et al., 2022b) and function composition (Andreas et al., 2016b).

Finally, modules can be trained jointly with the rest of the base model in multi-task learning (Caruana, 1997; Ruder, 2017), added sequentially in classic continual learning (Rusu et al., 2016), or integrated post-hoc into an already pre-trained and frozen model (Rebuffi et al., 2017; Houlsby et al., 2019). The last scenario is most common with current state-of-the-art models, which are trained as dense, fully shared models and may be 'modularised' after pre-training.

Crucially, this taxonomy reveals unexpected connections between several independent threads of research, including aggregation functions and mode connectivity (Frankle et al., 2020), routing and hypernetworks (Ha et al., 2017), among others.

We further illustrate a series of applications of modular networks in transfer learning across different areas such as natural language processing, computer vision, and speech processing. In addition, we show how modularity plays an important role in causal inference and discovery, programme simulation, and hierarchical reinforcement learning.

We hope that our overview will spark future research on modular deep learning in areas that may benefit from it such as community-driven efforts to develop and maintain machine learning technology.

## 8.3 Causal Discovery and Inference

Modularity in the design of a model may be assumed to reflect the modularity in the (physical) mechanisms of the world. In fact, a crucial assumption in causal inference (Schölkopf et al., 2012) is that such mechanisms underlying data generation are independent, as they do not influence each other, and reusable, as they may play a role in multiple distributions. Consequently, if one of the mechanisms, which defines a conditional distribution in the model graph, changes-possibly because of an intervention-the other modules remain invariant. If a machine learning model mirrors this modular structure, it is better suited to generalise in a sample-efficient way to new tasks: in fact, local distribution shifts require updating only the corresponding module parameters, which in turn results in faster adaptation (Bengio et al., 2020; Mittal et al., 2022).

The key challenge for this problem is how to specialise each module towards a specific mechanism based uniquely on observational data, especially when the number and nature of the mechanisms are unknown. Competition among the modules through topk routing (see § 4.2.2) is a common feature of many proposed

solutions. 24 Parascandolo et al. (2018) show how to invert causal independent mechanisms through a modular neural architecture, given data from the original distribution and an unlabelled mixture of their transformations (see Figure 10). Their model consists of a mixture of experts and an adversarial discriminator, which enforces that the inverted transformation lies in the support of the original distribution. Another architecture relying on module competition and capable of modelling sequential data is Recurrent Independent Mechanisms (RIMs; Goyal et al., 2021). Here, the modules are recurrent networks with separate parameters, each representing a different transition dynamics. However, their states are not entirely independent, as active modules are allowed to communicate through attention. This reflects a second assumption, namely that the dependencies among variables are highly sparse (Mittal et al., 2022). Attention can also serve to direct the flow of bottom-up and top-down information (Mittal et al., 2020).

Another challenge of neural causal discovery is jointly inducing abstract latent variables (such as objects or entities) from low-level perception (e.g., pixels of an image) while simultaneously learning the causal graph underlying such variables, which determines how they interact (Ke et al., 2021a). The lacklustre abilities of vanilla neural models to understand the compositional properties of symbolic building blocks, i.e. their 'binding problem', arguably explains their current shortfalls in systematic generalisation (Greff et al., 2020). Object-centric learning holds promise to mitigate these limitations. For instance, it can be facilitated by slot attention, which is a fully differentiable and iterative attention mechanism that interfaces between perceptual representations and slots, a set of unordered placeholder variables (Locatello et al., 2020). (Didolkar et al., 2021) propose Neural Production Systems, where rule templates can be bound to specific entities present in the working memory, in order to update their representations. In particular, rules are MLP modules and the matching with entities (triggering updates) is parameterised by attention.

Crucially, observational data alone is often 25 insufficient to learn structural causal models as they may not be identifiable (Pearl, 2009). Hence the necessity to augment observation with interventions and counterfactuals . These allow for answering questions about cause-effect relationships rather than mere correlations. In real-world scenarios, however, the nature and number of interventions are unknown Ke et al. (2021a). In this setting, there is no formal guarantee that causal discovery succeeds. Yet, Ke et al. (2019) finds that DAG discovery on interventional data based on continuous optimisation recovers causal graphs reliably. In particular, modular architectures surpass both vanilla models and graph neural networks (Ke et al., 2021a). Recently, Geffner et al. (2022) perform causal inference in a deep non-linear additive noise structural equation model, based on autoregressive flows. Variational inference is used to learn a posterior over causal graphs. The learned functions can be further used to estimate conditional average treatment effects based on simulations.

The main purpose of these deep modular methods is causal inference and discovery, which has applications in several branches of medicine and economics (Geffner et al., 2022). In addition, these methods are particularly relevant in grounded settings, where the distribution of the observations from the environment changes as the agent learns better policies (Goyal et al., 2021). Moreover, causal discovery can be combined with model-based RL methods to learn a self-supervised model of the environment, i.e. its variables and their causal dependencies, from trajectories of observations, actions, and rewards. This allows for simulating the potential outcomes of a policy before execution and thus estimating better value functions, which dramatically improves sample efficiency in agents (Ke et al., 2021a). Another common application of this family of modular neural architectures is out-of-distribution generalisation: for instance, zero-shot transfer to images of different sizes or sequences of different lengths (Goyal et al., 2021).

## 9 Conclusions

- · Modularity is defined as the functional specialisation of the components of a system.
- · Specialised sub-networks may emerge in vanilla neural modules (from multitask training or regularisation), but they are seldom reused and recombined.
- · Deep modular architectures rest on the separation between computation functions on the one hand and routing and aggregation functions on the other.
- · Computation functions may consist of any neural module. Modules may modify the original parameters , be concatenated to the input , or composed with the original function .
- · All composition strategies are equivalent to summing the original output with a term depending on the new module. In practice, however, they offer different trade-offs between efficiency (in time and space, during training and inference) and performance.
- · Routing controls the flow of information, i.e., module selection. In fixed routing, it is determined a priori based on expert knowledge. When this is not available, routing parameters are learned .
- · Learned routing is challenging because of training instability , module collapse , and overfitting . Thus, learned routing often underperforms fixed routing.
- · Routing can be conditioned on (parts of) the input or metadata such as task identity. Routing can take place at different levels , such as globally for the whole model or layer-wise.
- · Soft routing assigns every module a continuous score and performs a weighted combination of their outputs. It is amenable to being learned via gradient descent but is highly inefficient.
- · Hard routing activates only a subset of modules via top-1, topk , or variable-size selection. It is learned via reinforcement learning, evolutionary algorithms, or stochastic re-parameterisation. It corresponds to the principles of conditional computation and information bottleneck in cognition.
- · Hypernetworks can be interpreted as combining unnormalised routing (task embedding) with modules (generator). They can in turn generate parameters of other modules.
- · If routing selects multiple modules, these must be aggregated via a function.
- · Module parameters or outputs can be interpolated for aggregation, according to scores from the routing function, an attention mechanism, or via simple averaging.
- · Alternatively, aggregation may involve composing the module functions, either sequentially or based on a tree graph obtained from global routing.
- · The applications include parameter-efficient fine-tuning in NLP, computer vision, and speech processing. These rely on the same types of modules and fixed routing. In addition to increased efficiency, this prevents negative interference and enables zero-shot transfer.
- · Modularity also serves the purpose of generalising to new tasks systematically, by recombining modules and locally updating them.
- · Modular deep learning transcends the confines of private research: it enables community-driven sharing, expanding, reusing, and updating of the modules.
- · In hierarchical reinforcement learning , modular options serve as abstractions between task goals and low-level actions and observations. They facilitate planning in long-horizon and sparse-reward tasks and increase sample efficiency due to transferability.
- · In programme induction , the components of deep models can mirror a computer architecture: modules are elementary operations and routing is logical flow control. These are often augmented by an external read-write memory . Modules can also simulate symbolic algorithms.
- · In causal discovery and inference , modules may be taken to correspond to physical mechanisms that are independent and reusable.
- · Modular deep learning empowers these traditional applications by learning abstractions (options, programmes, causal graphs) end-to-end from perceptual stimuli .

