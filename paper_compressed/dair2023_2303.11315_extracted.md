## Abstract

Large language models (LLMs) encode parametric knowledge about world facts and have shown remarkable performance in knowledgedriven NLP tasks. However, their reliance on parametric knowledge may cause them to overlook contextual cues, leading to incorrect predictions in context-sensitive NLP tasks (e.g., knowledge acquisition tasks). In this paper, we seek to assess and enhance LLMs' contextual faithfulness in two aspects: knowledge conflict and prediction with abstention. We demonstrate that LLMs' faithfulness can be significantly improved using carefully designed prompting strategies. In particular, we identify opinion-based prompts and counterfactual demonstrations as the most effective methods. Opinion-based prompts reframe the context as a narrator's statement and inquire about the narrator's opinions, while counterfactual demonstrations use instances containing false facts to improve faithfulness in knowledge conflict situations. Neither technique requires additional training. We conduct experiments on three datasets of two standard NLP tasks, machine reading comprehension and relation extraction, and the results demonstrate significant improvement in faithfulness to contexts. 1

## 1 Introduction

Large language models (LLMs; Brown et al. 2020; Wei et al. 2022; Chowdhery et al. 2022; Chung et al. 2022) have made remarkable advances in solving various NLP problems, particularly in (context-free) knowledge-driven tasks such as question answering (Joshi et al., 2017; Kwiatkowski et al., 2019) and commonsense reasoning (Clark et al., 2018; Mihaylov et al., 2018). Without external context, LLMs can answer factual questions and achieve comparable results to supervised approaches (Brown et al., 2020; Wei et al., 2022), in-

## 3 Method

We focus on context-specific NLP tasks. The input of these tasks is formulated as ( c, q ) for free-form

generation tasks, where c is the context and q is the question, or ( c, q, o ) for tasks with close decision spaces (e.g., multi-choice tasks), where o is the set of decisions/choices. The desired output can be either a free-form text or a choice. We solve these tasks by prompting LLMs and study ways of designing prompting templates and demonstrations that are dedicated to improving the faithfulness of LLMs. Specifically, we find two proposed methods, opinion-based prompts and counterfactual demonstrations, to be the most effective ones. Our methods only change the prompts without finetuning the LLMs (Longpre et al., 2021; Li et al., 2022; Neeman et al., 2022), targeting a more general and affordable solution.

## 4.1 Experimental Setup

Our experiments are conducted using the InstructGPT model (text-davinci-003, 175B parameters) and LLama-2-7B-chat (Touvron et al., 2023). We use the base prompt as our baseline, and compare it against the proposed prompting templates described in §3.1, including attributed prompt (ATTR), instruction-based prompt (INSTR), opinion-based prompt (OPIN), and the combination of opinion-based prompt and instruction-based prompt (OPIN + INSTR). We evaluate the effectiveness of these templates in both zero-shot and

Table 1: Results (in %) on GPT-3.5-175B in the knowledge conflict setting. The overall best results are highlighted in bold . The best and the second best results in each setting are highlighted in green and orange , respectively.

| GPT-3.5      | MRC   | MRC   | MRC   | MRC   | RE    | RE    | RE    | RE    |
|--------------|-------|-------|-------|-------|-------|-------|-------|-------|
| GPT-3.5      | p s ↑ | p o ↓ | M R ↓ | EM ↑  | p s ↑ | p o ↓ | M R ↓ | F 1 ↑ |
| Base         | 59.0  | 32.1  | 35.2  | 6.2   | 73.9  | 21.5  | 22.5  | 81.0  |
| Attr         | 71.9  | 14.4  | 16.6  | 29.6  | 72.4  | 23.6  | 24.6  | 80.0  |
| Instr        | 74.2  | 16.0  | 17.7  | 27.1  | 75.8  | 15.6  | 17.1  | 81.6  |
| Opin         | 79.4  | 9.8   | 11.0  | 24.9  | 76.0  | 19.6  | 20.5  | 82.9  |
| Opin + Instr | 79.1  | 7.9   | 9.1   | 48.6  | 79.4  | 15.0  | 15.9  | 84.7  |
| Base         | 43.3  | 49.4  | 53.3  | 35.1  | 76.2  | 19.8  | 20.6  | 83.3  |
| Attr         | 54.1  | 37.7  | 41.0  | 45.5  | 76.5  | 19.7  | 20.5  | 83.7  |
| Instr        | 54.6  | 37.7  | 40.8  | 45.8  | 77.3  | 18.4  | 19.2  | 84.2  |
| Opin         | 60.6  | 28.7  | 32.1  | 51.1  | 76.8  | 18.4  | 19.3  | 83.8  |
| Opin + Instr | 64.7  | 26.8  | 29.3  | 53.8  | 78.2  | 17.1  | 17.9  | 84.9  |
| Base         | 86.9  | 6.5   | 7.0   | 80.2  | 78.7  | 13.7  | 14.8  | 83.9  |
| Attr         | 89.1  | 4.6   | 4.9   | 83.0  | 79.7  | 13.0  | 14.0  | 84.3  |
| Instr        | 86.2  | 6.3   | 6.8   | 80.1  | 78.0  | 12.8  | 14.1  | 82.9  |
| Opin         | 90.1  | 3.7   | 3.9   | 84.3  | 79.7  | 12.8  | 13.8  | 84.4  |
| Opin + Instr | 90.9  | 2.8   | 3.0   | 85.2  | 80.0  | 10.5  | 11.6  | 85.1  |

Table 2: Results (in %) on LLama-2-7B-chat in the knowledge conflict setting. The overall best results are highlighted in bold . The best and the second best results in each setting are highlighted in green and orange , respectively.

| LLama-2      | MRC       | MRC   | MRC   | MRC   | RE    | RE    | RE    | RE    |
|--------------|-----------|-------|-------|-------|-------|-------|-------|-------|
| LLama-2      | p s ↑     | p o ↓ | M R ↓ | EM ↑  | p s ↑ | p o ↓ | M R ↓ | F 1 ↑ |
| Base         | 50.8 40.9 |       | 44.6  | 3.5   | 15.3  | 67.6  | 81.6  | 12.8  |
| Attr         | 66.2 23.8 |       | 26.4  | 4.7   | 13.2  | 66.5  | 83.5  | 10.9  |
| Instr        | 77.7 19.7 |       | 20.2  | 27.0  | 19.6  | 9.2   | 75.1  | 13.2  |
| Opin         | 74.6 14.6 |       | 16.4  | 9.4   | 20.7  | 63.4  | 75.4  | 14.4  |
| Opin + Instr | 77.8 13.9 |       | 15.1  | 13.7  | 21.6  | 57.9  | 72.8  | 11.8  |
| Base         | 56.7 39.7 |       | 41.1  | 19.4  | 27.6  | 62.3  | 69.4  | 9.4   |
| Attr         | 61.7      | 34.5  | 35.9  | 25.2  | 29.4  | 58.9  | 66.7  | 11.2  |
| Instr        | 59.4 35.7 | 37.5  |       | 25.5  | 34.6  | 53.6  | 60.8  | 13.2  |
| Opin         | 67.1      | 32.1  | 32.4  | 18.5  | 32.2  | 57.1  | 63.9  | 10.9  |
| Opin + Instr | 70.6      | 26.8  | 27.5  | 27.6  | 35.7  | 51.3  | 59.0  | 11.5  |
| Base         | 84.4 7.8  |       | 8.4   | 39.2  | 76.3  | 14.8  | 16.2  | 38.9  |
| Attr         | 85.9      | 7.0   | 7.6   | 44.1  | 76.5  | 14.2  | 15.7  | 39.5  |
| Instr        | 85.5      | 6.7   | 7.3   | 47.1  | 76.0  | 14.4  | 15.9  | 37.3  |
| Opin         | 86.7      | 6.2   | 6.7   | 38.1  | 76.3  | 13.8  | 15.4  | 41.7  |
| Opin + Instr | 88.1      | 4.9   | 5.2   | 49.6  | 77.3  | 14.2  | 15.5  | 36.9  |

few-shot settings (with demonstrations).

## 4.4 Additional Analysis



## 4.5 Case Study

Tab. 5 shows some examples of prompts and the corresponding answers generated by text-davinci003. The left column of the table presents a knowledge conflict case where the original answer, Lady Gaga , is replaced with a counterfactual answer, Bosco . When using base prompts, LLM ignores the context and return the memorized answer Lady Gaga . However, using opinion-based prompts and their combination with instructions leads to a more faithful response, with the language model returning Bosco in the given context. The right column presents a scenario where the retrieved context from Google search is irrelevant to the given question. In such cases, base prompts still return a choice, leading to a potentially incorrect answer. However, opinion-based prompts and their combination with instructions can abstain from making predictions and return I don't know . These examples demonstrate the effectiveness of proposed

Table 5: Examples of prompts and LLMs' corresponding predictions. In the 'Prompt' row, we show and highlight the added parts from different prompting templates including attributed prompts, instruction-based prompts, and opinion-based prompts.

|              | Knowledge Conflict                                                                                                                                                                                                                                                                              | Prediction with Abstention                                                                                                                                                                                                                             |
|--------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Context      | (Counterfactual passage) The Super Bowl LI Half- time show took place on February 5, 2017, at NRG Stadium in Houston, Texas as part of Super Bowl LI. The show was headlined by Bosco , who performed a medley of her songs, including newer material from her most recent studio album Joanne. | Tara Connolly is senior gas campaigner at Global Witness, an international NGO working towards a more sustainable, just and equal planet. She has over a decade of experience in EU energy policy. The views expressed in this commentary are her own. |
| Prompt       | Instruction: read the given information and answer the corresponding question. Q: who performed the halftime show at Super Bowl                                                                                                                                                                 | Instruction: answer a question based on the provided input-output pairs. Bob said, 'Tara Connolly ... are her own.'                                                                                                                                    |
|              | Bob said, 'The Super Bowl ... album Joanne.' 51 in Bob's opinion based on the given text?                                                                                                                                                                                                       | Q: Mo Farah made public that he was trafficked from which African country to the UK in Bob's opinion based on the given text?                                                                                                                          |
| Base         | Lady Gaga ✗                                                                                                                                                                                                                                                                                     | Somalia ✗                                                                                                                                                                                                                                              |
| Attr         | Lady Gaga ✗                                                                                                                                                                                                                                                                                     | Somalia ✗                                                                                                                                                                                                                                              |
| Instr        | Lady Gaga ✗                                                                                                                                                                                                                                                                                     | Somaliland ✗                                                                                                                                                                                                                                           |
| Opin         | Bosco ✓                                                                                                                                                                                                                                                                                         | I don't know ✓                                                                                                                                                                                                                                         |
| Instr + Opin | Bosco ✓                                                                                                                                                                                                                                                                                         | I don't know ✓                                                                                                                                                                                                                                         |
| Answer       | Bosco                                                                                                                                                                                                                                                                                           |                                                                                                                                                                                                                                                        |
|              |                                                                                                                                                                                                                                                                                                 | I don't know                                                                                                                                                                                                                                           |

prompts in generating context-faithful responses.

## 5 Conclusion

In this paper, we focus on addressing the faithfulness issue of LLMs in context-specific NLP tasks, particularly in scenarios with knowledge conflict and prediction with abstention. We propose that two methods, opinion-based prompts and counterfactual demonstrations, are effective in improving LLMs' faithfulness to contexts. We evaluate our methods on three datasets of two tasks, namely machine reading comprehension and relation extraction, and observed significant improvement in faithfulness to contexts. Future work includes evaluating the effectiveness of proposed methods on a broader range of NLP tasks such as open-domain QA and summarization, and studying other techniques to improve faithfulness further.

## Limitations

In this study, our main focus is on the utilization of context-augmented prompting, assuming the reliability of the provided context. However, real-world scenarios can be more complicated, which may involve retrieved contexts that contain erroneous or conflicting information. Assessing the factuality of the context solely based on the provided information becomes challenging, as it depends on additional factors such as trustworthiness and timeliness of the information source. Due to the complexity and challenges associated with verifying context reliability, we do not address this issue within the scope of this work. Furthermore, it is important to note that our paper primarily concentrates on the capability of LLMs to generate updated answers or decisions for given questions, rather than exploring more intricate tasks that require the model to apply the updated knowledge in multi-hop reasoning.

