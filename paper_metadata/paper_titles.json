{
    "2305.18290v3": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model",
    "2308.04079v1": "3D Gaussian Splatting for Real-Time Radiance Field Rendering",
    "2308.08155v2": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation",
    "2308.12950v3": "Code Llama: Open Foundation Models for Code",
    "2308.12966v3": "Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond",
    "2309.06180v1": "Efficient Memory Management for Large Language Model Serving with PagedAttention",
    "2309.16609v1": "Qwen Technical Report",
    "2310.03744v2": "Improved Baselines with Visual Instruction Tuning",
    "2310.06825v1": "Mistral 7B",
    "2310.16944v1": "Zephyr: Direct Distillation of LM Alignment",
    "2311.05232v2": "A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions",
    "2311.15127v1": "Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets",
    "2311.16867v2": "The Falcon Series of Open Language Models",
    "2312.00752v2": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces",
    "2312.11805v4": "Gemini: A Family of Highly Capable Multimodal Models",
    "2312.14238v3": "InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks",
    "2401.04088v1": "Mixtral of Experts",
    "2401.09417v3": "Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model",
    "2401.10166v3": "VMamba: Visual State Space Model",
    "2401.13387v2": "A Mathematical Theory of Semantic Communication",
    "2401.14196v2": "DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence",
    "2403.03206v1": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis",
    "2403.04132v1": "Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference",
    "2403.05530v5": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
    "2403.08295v4": "Gemma: Open Models Based on Gemini Research and Technology",
    "2404.14219v4": "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone",
    "2407.10671v4": "Qwen2 Technical Report",
    "2407.21783v3": "The Llama 3 Herd of Models"
}